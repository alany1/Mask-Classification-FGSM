{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here.\n",
    "\n",
    "Please make sure if you are running this notebook in the workspace that you have chosen GPU rather than CPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt2 \n",
    "import seaborn as sb\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import random as rn\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from PIL import Image\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "#del variables\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The data should be included alongside this notebook, otherwise you can [download it here](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz). The dataset is split into three parts, training, validation, and testing. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annotations', 'images']\n",
      "Image path = masks\\images\n",
      "Total number of images : 853\n",
      "Annotation path = masks/annotations\n",
      "Total Annotation files are 853\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "import os\n",
    "Dirname = []\n",
    "Filenames =[]\n",
    "for dirname, _, filenames in os.walk('masks'):\n",
    "    for filename in filenames:\n",
    "        Dirname.append(dirname)\n",
    "        Filenames.append(filename)\n",
    "        X = os.path.join(dirname, filename)\n",
    "#print(Filenames)        \n",
    "        \n",
    "Dir = 'masks'\n",
    "print(os.listdir(Dir))\n",
    "images_path = os.path.join(Dir,'images')\n",
    "print(\"Image path = {}\".format(images_path))\n",
    "print(\"Total number of images : {}\".format(len(os.listdir(images_path))))\n",
    "Annotation_path = 'masks/annotations'\n",
    "print(\"Annotation path = {}\".format(Annotation_path))\n",
    "print(\"Total Annotation files are {}\".format(len(os.listdir(Annotation_path))))\n",
    "\n",
    "Image_width = 80\n",
    "Image_height = 80\n",
    "Image_array = []\n",
    "Labels = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Check label files are according to images files\n",
    "Sorted_files = sorted(os.listdir(Annotation_path))\n",
    "#print(Sorted_files)\n",
    "Sorted_images_path = sorted(os.listdir(images_path))\n",
    "#print(Sorted_images_path)\n",
    "\n",
    "# Prepare data and respective labels\n",
    "def get_box(obj):\n",
    "    \n",
    "    xmin = int(obj.find('xmin').text)\n",
    "    ymin = int(obj.find('ymin').text)\n",
    "    xmax = int(obj.find('xmax').text)\n",
    "    ymax = int(obj.find('ymax').text)\n",
    "    \n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "M = {'without_mask':1, 'with_mask':2, 'mask_weared_incorrect':3}\n",
    "M_i = {1: 'without_mask', 2: 'with_mask', 3: 'mask_weared_incorrect'}\n",
    "count = 0\n",
    "for i,file in enumerate(tqdm(sorted(os.listdir(Annotation_path)),desc='Preparing data..')):\n",
    "    file_path = Annotation_path + \"/\" + file\n",
    "    xml = ET.parse(file_path)\n",
    "    root = xml.getroot()\n",
    "    image_path = images_path + \"/\" + root[1].text\n",
    "\n",
    "    temp = []\n",
    "    for j,bndbox in enumerate(root.iter('bndbox')):\n",
    "        [xmin, ymin, xmax, ymax] = get_box(bndbox)\n",
    "        img = cv2.imread(image_path)\n",
    "        face_img = img[ymin:ymax,xmin:xmax]\n",
    "        face_img  = cv2.resize(face_img,(Image_width,Image_height))\n",
    "        \n",
    "        temp.append(Image.fromarray(face_img))\n",
    "\n",
    "        Image_array.append(np.array(face_img)) \n",
    "            \n",
    "    for k,obj in enumerate(root.findall('object')):\n",
    "        name = obj.find('name').text \n",
    "        p = np.random.random()\n",
    "#         if p < .7:\n",
    "#             temp[k].save(f\"mask_data/train/{M[name]}/image_{count}.png\")\n",
    "#         elif p < .85: \n",
    "#             temp[k].save(f\"mask_data/valid/{M[name]}/image_{count}.png\")\n",
    "#         else:\n",
    "#             temp[k].save(f\"mask_data/test/{M[name]}/image_{count}.png\")\n",
    "        temp[k].save(f\"all_data/{M[name]}/image_{count}.png\")\n",
    "        count+=1\n",
    "        Labels.append(np.array(name)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import glob\n",
    "import shutil\n",
    "without_mask = 'all_data/1'\n",
    "with_mask = 'all_data/2'\n",
    "mask_weared_incorrect = 'all_data/3'\n",
    "count = 0\n",
    "for i,image_path in enumerate(glob.glob(f\"{without_mask}/*\")):\n",
    "    p = np.random.random()\n",
    "    #img = cv2.imread(image_path)\n",
    "    #img_arr = Image.fromarray(img)\n",
    "    if p<.7:\n",
    "        shutil.copyfile(image_path,f\"mask_data/train/1/image_{count}.png\")\n",
    "        #img_arr.save(f\"mask_data/train/1/image_{count}.png\")\n",
    "    elif p < .85:\n",
    "        shutil.copyfile(image_path,f\"mask_data/test/1/image_{count}.png\")\n",
    "        #img_arr.save(f\"mask_data/test/1/image_{count}.png\")\n",
    "    else:\n",
    "        shutil.copyfile(image_path,f\"mask_data/valid/1/image_{count}.png\")        #img_arr.save(f\"mask_data/valid/1/image_{count}.png\")\n",
    "    count += 1\n",
    "for i,image_path in enumerate(glob.glob(f\"{with_mask}/*\")):\n",
    "    p = np.random.random()\n",
    "    #img = cv2.imread(image_path)\n",
    "    #img_arr = Image.fromarray(img)\n",
    "    if p<.7:\n",
    "        shutil.copyfile(image_path,f\"mask_data/train/2/image_{count}.png\")\n",
    "        #img_arr.save(f\"mask_data/train/1/image_{count}.png\")\n",
    "    elif p < .85:\n",
    "        shutil.copyfile(image_path,f\"mask_data/test/2/image_{count}.png\")\n",
    "        #img_arr.save(f\"mask_data/test/1/image_{count}.png\")\n",
    "    else:\n",
    "        shutil.copyfile(image_path,f\"mask_data/valid/2/image_{count}.png\")        #img_arr.save(f\"mask_data/valid/1/image_{count}.png\")\n",
    "    count += 1\n",
    "for i,image_path in enumerate(glob.glob(f\"{mask_weared_incorrect}/*\")):\n",
    "    p = np.random.random()\n",
    "    #img = cv2.imread(image_path)\n",
    "    #img_arr = Image.fromarray(img)\n",
    "    if p<.7:\n",
    "        shutil.copyfile(image_path,f\"mask_data/train/3/image_{count}.png\")\n",
    "        #img_arr.save(f\"mask_data/train/1/image_{count}.png\")\n",
    "    elif p < .85:\n",
    "        shutil.copyfile(image_path,f\"mask_data/test/3/image_{count}.png\")\n",
    "        #img_arr.save(f\"mask_data/test/1/image_{count}.png\")\n",
    "    else:\n",
    "        shutil.copyfile(image_path,f\"mask_data/valid/3/image_{count}.png\")        #img_arr.save(f\"mask_data/valid/1/image_{count}.png\")\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fdc2259c48bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Check the total Images and label length are equal \n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "#Check random images \n",
    "fig,ax = plt.subplots(4,4)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        l = rn.randint(0,len(Labels))\n",
    "        \n",
    "        image = cv2.cvtColor(Image_array[l], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        ax[i,j].imshow(image)\n",
    "        ax[i,j].set_title(Labels[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'mask_data'\n",
    "all_data = 'all_data'\n",
    "\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor): \n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the training, validation, and testing sets\n",
    "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                          transforms.Resize(256),#transforms.RandomResizedCrop(224),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "# training_transforms = transforms.Compose([transforms.Resize(256),#transforms.RandomResizedCrop(224),\n",
    "#                                           transforms.CenterCrop(224),\n",
    "#                                           transforms.RandomHorizontalFlip(),\n",
    "#                                           transforms.ToTensor(),\n",
    "#                                           transforms.Normalize([0.485, 0.456, 0.406], \n",
    "#                                                                [0.229, 0.224, 0.225]),\n",
    "#                                           AddGaussianNoise(0.1,0.08)])\n",
    "\n",
    "\n",
    "# training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "#                                           transforms.RandomResizedCrop(224),\n",
    "#                                           transforms.RandomHorizontalFlip(),\n",
    "#                                           transforms.ToTensor(),\n",
    "#                                           transforms.Normalize([0.485, 0.456, 0.406], \n",
    "#                                                                [0.229, 0.224, 0.225]),\n",
    "#                                           AddGaussianNoise(0.1,0.08)])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                              [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "\n",
    "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
    "#training_dataset = datasets.ImageFolder(all_data,transform = training_transforms)\n",
    "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
    "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `flower_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n",
    "\n",
    "One last important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train your network\n",
    "# Transfer Learning\n",
    "model = models.vgg19(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained model parameters to avoid backpropogating through them\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Build custom classifier\n",
    "# classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000, bias= True)),\n",
    "#                                         ('tanh1', nn.Tanh()),\n",
    "#                                         ('drop', nn.Dropout(p=0.5)),\n",
    "#                                         ('fc2', nn.Linear(5000,1000, bias = True)),\n",
    "#                                         ('tanh2', nn.Tanh()),\n",
    "#                                         ('fc3',nn.Linear(1000,100, bias=True)),\n",
    "#                                         ('tanh3',nn.Tanh()),\n",
    "#                                         ('fc4',nn.Linear(100,3,bias=True)),\n",
    "#                                         ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 10, bias= True)),\n",
    "                                        ('tanh1', nn.Tanh()),\n",
    "                                        ('dropout', nn.Dropout(p=0.25)),\n",
    "                                        ('fc2',nn.Linear(10,2,bias=True)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ce8001a280>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    \n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for images, labels in iter(validateloader):\n",
    "\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        output = model.forward(images)\n",
    "        val_loss += criterion(output, labels).item()\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        \n",
    "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return val_loss, accuracy\n",
    "plt.plot(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 2.4872e-04, -5.0347e-03,  2.8958e-03,  ..., -1.5246e-03,\n",
      "          2.0949e-03, -2.7043e-03],\n",
      "        [-1.2478e-03, -2.4606e-03, -4.8648e-03,  ..., -1.9065e-03,\n",
      "          2.8141e-03,  5.9423e-03],\n",
      "        [ 1.6865e-03,  8.1474e-04,  3.8727e-04,  ...,  4.5558e-03,\n",
      "          2.2424e-03, -4.0377e-03],\n",
      "        ...,\n",
      "        [ 2.5106e-03,  1.9248e-04,  1.0981e-03,  ...,  3.0176e-03,\n",
      "         -2.1343e-03, -9.1571e-05],\n",
      "        [ 5.1262e-03, -5.8643e-03,  5.5755e-03,  ...,  1.5092e-03,\n",
      "          2.7672e-03, -3.3381e-03],\n",
      "        [-6.3043e-03,  5.1155e-03,  9.0467e-05,  ...,  3.5951e-03,\n",
      "         -2.5397e-03, -1.2424e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0007, -0.0025, -0.0060, -0.0062,  0.0033, -0.0054,  0.0047, -0.0021,\n",
      "         0.0059,  0.0007], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0716, -0.0817, -0.1897,  0.2473,  0.2214,  0.0078,  0.0160, -0.2358,\n",
      "         -0.0905,  0.1052],\n",
      "        [-0.1671,  0.1101, -0.1359, -0.0251, -0.1508, -0.2815,  0.1775, -0.0312,\n",
      "         -0.3078, -0.0575]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2506, -0.1773], requires_grad=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function and gradient descent\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "print(list(model.classifier.parameters()))\n",
    "\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "Epoch: 1/6..  Training Loss: 0.000..  Validation Loss: 0.732..  Validation Accuracy: 0.325\n",
      "[]\n",
      "finished epoch 0 step 1\n",
      "[]\n",
      "finished epoch 0 step 2\n",
      "[]\n",
      "finished epoch 0 step 3\n",
      "[]\n",
      "finished epoch 0 step 4\n",
      "[]\n",
      "finished epoch 0 step 5\n",
      "[]\n",
      "finished epoch 0 step 6\n",
      "[]\n",
      "finished epoch 0 step 7\n",
      "[]\n",
      "finished epoch 0 step 8\n",
      "[]\n",
      "finished epoch 0 step 9\n",
      "[]\n",
      "finished epoch 0 step 10\n",
      "[]\n",
      "finished epoch 0 step 11\n",
      "[]\n",
      "finished epoch 0 step 12\n",
      "[]\n",
      "finished epoch 0 step 13\n",
      "[]\n",
      "finished epoch 0 step 14\n",
      "[]\n",
      "finished epoch 0 step 15\n",
      "[]\n",
      "finished epoch 0 step 16\n",
      "[]\n",
      "finished epoch 0 step 17\n",
      "[]\n",
      "finished epoch 0 step 18\n",
      "[]\n",
      "finished epoch 0 step 19\n",
      "[]\n",
      "finished epoch 0 step 20\n",
      "[]\n",
      "finished epoch 0 step 21\n",
      "[]\n",
      "finished epoch 0 step 22\n",
      "[]\n",
      "finished epoch 0 step 23\n",
      "[]\n",
      "finished epoch 0 step 24\n",
      "[]\n",
      "finished epoch 0 step 25\n",
      "[]\n",
      "finished epoch 0 step 26\n",
      "[]\n",
      "finished epoch 0 step 27\n",
      "[]\n",
      "finished epoch 0 step 28\n",
      "[]\n",
      "finished epoch 0 step 29\n",
      "[]\n",
      "finished epoch 0 step 30\n",
      "[]\n",
      "finished epoch 0 step 31\n",
      "[]\n",
      "finished epoch 0 step 32\n",
      "[]\n",
      "finished epoch 0 step 33\n",
      "[]\n",
      "finished epoch 0 step 34\n",
      "[]\n",
      "finished epoch 0 step 35\n",
      "[]\n",
      "finished epoch 0 step 36\n",
      "[]\n",
      "finished epoch 0 step 37\n",
      "[]\n",
      "finished epoch 0 step 38\n",
      "[]\n",
      "finished epoch 0 step 39\n",
      "[]\n",
      "finished epoch 0 step 40\n",
      "[]\n",
      "finished epoch 0 step 41\n",
      "[]\n",
      "finished epoch 0 step 42\n",
      "[]\n",
      "finished epoch 0 step 43\n",
      "[]\n",
      "finished epoch 0 step 44\n",
      "[]\n",
      "finished epoch 0 step 45\n",
      "[]\n",
      "finished epoch 0 step 46\n",
      "[]\n",
      "finished epoch 0 step 47\n",
      "[]\n",
      "finished epoch 0 step 48\n",
      "[]\n",
      "finished epoch 0 step 49\n",
      "[]\n",
      "finished epoch 0 step 50\n",
      "[]\n",
      "finished epoch 0 step 51\n",
      "[]\n",
      "finished epoch 0 step 52\n",
      "[]\n",
      "finished epoch 0 step 53\n",
      "[]\n",
      "finished epoch 0 step 54\n",
      "[]\n",
      "finished epoch 0 step 55\n",
      "[]\n",
      "finished epoch 0 step 56\n",
      "[]\n",
      "finished epoch 0 step 57\n",
      "[]\n",
      "finished epoch 0 step 58\n",
      "[]\n",
      "finished epoch 0 step 59\n",
      "[]\n",
      "finished epoch 0 step 60\n",
      "[]\n",
      "finished epoch 0 step 61\n",
      "[]\n",
      "finished epoch 0 step 62\n",
      "[]\n",
      "finished epoch 0 step 63\n",
      "[]\n",
      "finished epoch 0 step 64\n",
      "[]\n",
      "finished epoch 0 step 65\n",
      "[]\n",
      "finished epoch 0 step 66\n",
      "[]\n",
      "finished epoch 0 step 67\n",
      "[]\n",
      "finished epoch 0 step 68\n",
      "[]\n",
      "finished epoch 0 step 69\n",
      "[]\n",
      "finished epoch 0 step 70\n",
      "[]\n",
      "finished epoch 0 step 71\n",
      "[]\n",
      "finished epoch 0 step 72\n",
      "[]\n",
      "finished epoch 0 step 73\n",
      "[]\n",
      "finished epoch 0 step 74\n",
      "[]\n",
      "finished epoch 0 step 75\n",
      "[]\n",
      "finished epoch 0 step 76\n",
      "[]\n",
      "finished epoch 0 step 77\n",
      "[]\n",
      "finished epoch 0 step 78\n",
      "[]\n",
      "finished epoch 0 step 79\n",
      "[]\n",
      "finished epoch 0 step 80\n",
      "[]\n",
      "finished epoch 0 step 81\n",
      "[]\n",
      "finished epoch 0 step 82\n",
      "[]\n",
      "finished epoch 0 step 83\n",
      "[]\n",
      "finished epoch 0 step 84\n",
      "[]\n",
      "finished epoch 0 step 85\n",
      "[]\n",
      "finished epoch 0 step 86\n",
      "[]\n",
      "finished epoch 0 step 87\n",
      "[]\n",
      "finished epoch 0 step 88\n",
      "[]\n",
      "finished epoch 0 step 89\n",
      "[]\n",
      "finished epoch 0 step 90\n",
      "[]\n",
      "finished epoch 0 step 91\n",
      "[]\n",
      "finished epoch 0 step 92\n",
      "[]\n",
      "finished epoch 0 step 93\n",
      "[]\n",
      "finished epoch 0 step 94\n",
      "[]\n",
      "finished epoch 0 step 95\n",
      "[]\n",
      "finished epoch 0 step 96\n",
      "[]\n",
      "finished epoch 0 step 97\n",
      "[]\n",
      "finished epoch 0 step 98\n",
      "[]\n",
      "finished epoch 0 step 99\n",
      "[]\n",
      "finished epoch 0 step 100\n",
      "Epoch: 1/6..  Training Loss: 0.236..  Validation Loss: 0.137..  Validation Accuracy: 0.950\n",
      "[]\n",
      "finished epoch 0 step 101\n",
      "[]\n",
      "finished epoch 0 step 102\n",
      "[]\n",
      "finished epoch 0 step 103\n",
      "[]\n",
      "finished epoch 0 step 104\n",
      "[]\n",
      "finished epoch 0 step 105\n",
      "[]\n",
      "finished epoch 0 step 106\n",
      "[]\n",
      "finished epoch 0 step 107\n",
      "[]\n",
      "finished epoch 0 step 108\n",
      "[]\n",
      "finished epoch 0 step 109\n",
      "[]\n",
      "finished epoch 0 step 110\n",
      "[]\n",
      "finished epoch 0 step 111\n",
      "[]\n",
      "finished epoch 0 step 112\n",
      "[]\n",
      "finished epoch 0 step 113\n",
      "[]\n",
      "finished epoch 0 step 114\n",
      "[]\n",
      "finished epoch 0 step 115\n",
      "[]\n",
      "finished epoch 0 step 116\n",
      "[]\n",
      "finished epoch 0 step 117\n",
      "[]\n",
      "finished epoch 0 step 118\n",
      "[]\n",
      "finished epoch 0 step 119\n",
      "[]\n",
      "finished epoch 0 step 120\n",
      "[]\n",
      "finished epoch 0 step 121\n",
      "[]\n",
      "finished epoch 0 step 122\n",
      "[]\n",
      "finished epoch 0 step 123\n",
      "[]\n",
      "finished epoch 0 step 124\n",
      "[]\n",
      "finished epoch 0 step 125\n",
      "[]\n",
      "finished epoch 0 step 126\n",
      "[]\n",
      "finished epoch 0 step 127\n",
      "[]\n",
      "finished epoch 0 step 128\n",
      "[]\n",
      "finished epoch 0 step 129\n",
      "[]\n",
      "finished epoch 0 step 130\n",
      "[]\n",
      "finished epoch 0 step 131\n",
      "[]\n",
      "finished epoch 0 step 132\n",
      "[]\n",
      "finished epoch 0 step 133\n",
      "[]\n",
      "finished epoch 0 step 134\n",
      "[]\n",
      "finished epoch 0 step 135\n",
      "[]\n",
      "finished epoch 0 step 136\n",
      "[]\n",
      "finished epoch 0 step 137\n",
      "[]\n",
      "finished epoch 0 step 138\n",
      "[]\n",
      "finished epoch 0 step 139\n",
      "[]\n",
      "finished epoch 0 step 140\n",
      "[]\n",
      "finished epoch 0 step 141\n",
      "[]\n",
      "finished epoch 0 step 142\n",
      "[]\n",
      "finished epoch 0 step 143\n",
      "[]\n",
      "finished epoch 0 step 144\n",
      "[]\n",
      "finished epoch 0 step 145\n",
      "[]\n",
      "finished epoch 0 step 146\n",
      "[]\n",
      "finished epoch 0 step 147\n",
      "[]\n",
      "finished epoch 0 step 148\n",
      "[]\n",
      "finished epoch 0 step 149\n",
      "[]\n",
      "finished epoch 0 step 150\n",
      "[]\n",
      "finished epoch 0 step 151\n",
      "[]\n",
      "finished epoch 0 step 152\n",
      "[]\n",
      "finished epoch 0 step 153\n",
      "[]\n",
      "finished epoch 0 step 154\n",
      "[]\n",
      "finished epoch 0 step 155\n",
      "[]\n",
      "finished epoch 0 step 156\n",
      "[]\n",
      "finished epoch 0 step 157\n",
      "[]\n",
      "finished epoch 0 step 158\n",
      "[]\n",
      "finished epoch 0 step 159\n",
      "[]\n",
      "finished epoch 0 step 160\n",
      "[]\n",
      "finished epoch 0 step 161\n",
      "[]\n",
      "finished epoch 0 step 162\n",
      "[]\n",
      "finished epoch 0 step 163\n",
      "[]\n",
      "finished epoch 0 step 164\n",
      "[]\n",
      "finished epoch 0 step 165\n",
      "[]\n",
      "finished epoch 0 step 166\n",
      "[]\n",
      "finished epoch 0 step 167\n",
      "[]\n",
      "finished epoch 0 step 168\n",
      "[]\n",
      "finished epoch 0 step 169\n",
      "[]\n",
      "finished epoch 0 step 170\n",
      "[]\n",
      "finished epoch 0 step 171\n",
      "[]\n",
      "finished epoch 0 step 172\n",
      "[]\n",
      "finished epoch 0 step 173\n",
      "[]\n",
      "finished epoch 0 step 174\n",
      "[]\n",
      "finished epoch 0 step 175\n",
      "[]\n",
      "finished epoch 0 step 176\n",
      "[]\n",
      "finished epoch 0 step 177\n",
      "[]\n",
      "finished epoch 0 step 178\n",
      "[]\n",
      "finished epoch 0 step 179\n",
      "[]\n",
      "finished epoch 0 step 180\n",
      "[]\n",
      "finished epoch 0 step 181\n",
      "[]\n",
      "finished epoch 0 step 182\n",
      "[]\n",
      "finished epoch 1 step 183\n",
      "[]\n",
      "finished epoch 1 step 184\n",
      "[]\n",
      "finished epoch 1 step 185\n",
      "[]\n",
      "finished epoch 1 step 186\n",
      "[]\n",
      "finished epoch 1 step 187\n",
      "[]\n",
      "finished epoch 1 step 188\n",
      "[]\n",
      "finished epoch 1 step 189\n",
      "[]\n",
      "finished epoch 1 step 190\n",
      "[]\n",
      "finished epoch 1 step 191\n",
      "[]\n",
      "finished epoch 1 step 192\n",
      "[]\n",
      "finished epoch 1 step 193\n",
      "[]\n",
      "finished epoch 1 step 194\n",
      "[]\n",
      "finished epoch 1 step 195\n",
      "[]\n",
      "finished epoch 1 step 196\n",
      "[]\n",
      "finished epoch 1 step 197\n",
      "[]\n",
      "finished epoch 1 step 198\n",
      "[]\n",
      "finished epoch 1 step 199\n",
      "[]\n",
      "finished epoch 1 step 200\n",
      "Epoch: 2/6..  Training Loss: 0.019..  Validation Loss: 0.099..  Validation Accuracy: 0.971\n",
      "[]\n",
      "finished epoch 1 step 201\n",
      "[]\n",
      "finished epoch 1 step 202\n",
      "[]\n",
      "finished epoch 1 step 203\n",
      "[]\n",
      "finished epoch 1 step 204\n",
      "[]\n",
      "finished epoch 1 step 205\n",
      "[]\n",
      "finished epoch 1 step 206\n",
      "[]\n",
      "finished epoch 1 step 207\n",
      "[]\n",
      "finished epoch 1 step 208\n",
      "[]\n",
      "finished epoch 1 step 209\n",
      "[]\n",
      "finished epoch 1 step 210\n",
      "[]\n",
      "finished epoch 1 step 211\n",
      "[]\n",
      "finished epoch 1 step 212\n",
      "[]\n",
      "finished epoch 1 step 213\n",
      "[]\n",
      "finished epoch 1 step 214\n",
      "[]\n",
      "finished epoch 1 step 215\n",
      "[]\n",
      "finished epoch 1 step 216\n",
      "[]\n",
      "finished epoch 1 step 217\n",
      "[]\n",
      "finished epoch 1 step 218\n",
      "[]\n",
      "finished epoch 1 step 219\n",
      "[]\n",
      "finished epoch 1 step 220\n",
      "[]\n",
      "finished epoch 1 step 221\n",
      "[]\n",
      "finished epoch 1 step 222\n",
      "[]\n",
      "finished epoch 1 step 223\n",
      "[]\n",
      "finished epoch 1 step 224\n",
      "[]\n",
      "finished epoch 1 step 225\n",
      "[]\n",
      "finished epoch 1 step 226\n",
      "[]\n",
      "finished epoch 1 step 227\n",
      "[]\n",
      "finished epoch 1 step 228\n",
      "[]\n",
      "finished epoch 1 step 229\n",
      "[]\n",
      "finished epoch 1 step 230\n",
      "[]\n",
      "finished epoch 1 step 231\n",
      "[]\n",
      "finished epoch 1 step 232\n",
      "[]\n",
      "finished epoch 1 step 233\n",
      "[]\n",
      "finished epoch 1 step 234\n",
      "[]\n",
      "finished epoch 1 step 235\n",
      "[]\n",
      "finished epoch 1 step 236\n",
      "[]\n",
      "finished epoch 1 step 237\n",
      "[]\n",
      "finished epoch 1 step 238\n",
      "[]\n",
      "finished epoch 1 step 239\n",
      "[]\n",
      "finished epoch 1 step 240\n",
      "[]\n",
      "finished epoch 1 step 241\n",
      "[]\n",
      "finished epoch 1 step 242\n",
      "[]\n",
      "finished epoch 1 step 243\n",
      "[]\n",
      "finished epoch 1 step 244\n",
      "[]\n",
      "finished epoch 1 step 245\n",
      "[]\n",
      "finished epoch 1 step 246\n",
      "[]\n",
      "finished epoch 1 step 247\n",
      "[]\n",
      "finished epoch 1 step 248\n",
      "[]\n",
      "finished epoch 1 step 249\n",
      "[]\n",
      "finished epoch 1 step 250\n",
      "[]\n",
      "finished epoch 1 step 251\n",
      "[]\n",
      "finished epoch 1 step 252\n",
      "[]\n",
      "finished epoch 1 step 253\n",
      "[]\n",
      "finished epoch 1 step 254\n",
      "[]\n",
      "finished epoch 1 step 255\n",
      "[]\n",
      "finished epoch 1 step 256\n",
      "[]\n",
      "finished epoch 1 step 257\n",
      "[]\n",
      "finished epoch 1 step 258\n",
      "[]\n",
      "finished epoch 1 step 259\n",
      "[]\n",
      "finished epoch 1 step 260\n",
      "[]\n",
      "finished epoch 1 step 261\n",
      "[]\n",
      "finished epoch 1 step 262\n",
      "[]\n",
      "finished epoch 1 step 263\n",
      "[]\n",
      "finished epoch 1 step 264\n",
      "[]\n",
      "finished epoch 1 step 265\n",
      "[]\n",
      "finished epoch 1 step 266\n",
      "[]\n",
      "finished epoch 1 step 267\n",
      "[]\n",
      "finished epoch 1 step 268\n",
      "[]\n",
      "finished epoch 1 step 269\n",
      "[]\n",
      "finished epoch 1 step 270\n",
      "[]\n",
      "finished epoch 1 step 271\n",
      "[]\n",
      "finished epoch 1 step 272\n",
      "[]\n",
      "finished epoch 1 step 273\n",
      "[]\n",
      "finished epoch 1 step 274\n",
      "[]\n",
      "finished epoch 1 step 275\n",
      "[]\n",
      "finished epoch 1 step 276\n",
      "[]\n",
      "finished epoch 1 step 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "finished epoch 1 step 278\n",
      "[]\n",
      "finished epoch 1 step 279\n",
      "[]\n",
      "finished epoch 1 step 280\n",
      "[]\n",
      "finished epoch 1 step 281\n",
      "[]\n",
      "finished epoch 1 step 282\n",
      "[]\n",
      "finished epoch 1 step 283\n",
      "[]\n",
      "finished epoch 1 step 284\n",
      "[]\n",
      "finished epoch 1 step 285\n",
      "[]\n",
      "finished epoch 1 step 286\n",
      "[]\n",
      "finished epoch 1 step 287\n",
      "[]\n",
      "finished epoch 1 step 288\n",
      "[]\n",
      "finished epoch 1 step 289\n",
      "[]\n",
      "finished epoch 1 step 290\n",
      "[]\n",
      "finished epoch 1 step 291\n",
      "[]\n",
      "finished epoch 1 step 292\n",
      "[]\n",
      "finished epoch 1 step 293\n",
      "[]\n",
      "finished epoch 1 step 294\n",
      "[]\n",
      "finished epoch 1 step 295\n",
      "[]\n",
      "finished epoch 1 step 296\n",
      "[]\n",
      "finished epoch 1 step 297\n",
      "[]\n",
      "finished epoch 1 step 298\n",
      "[]\n",
      "finished epoch 1 step 299\n",
      "[]\n",
      "finished epoch 1 step 300\n",
      "Epoch: 2/6..  Training Loss: 0.119..  Validation Loss: 0.096..  Validation Accuracy: 0.972\n",
      "[]\n",
      "finished epoch 1 step 301\n",
      "[]\n",
      "finished epoch 1 step 302\n",
      "[]\n",
      "finished epoch 1 step 303\n",
      "[]\n",
      "finished epoch 1 step 304\n",
      "[]\n",
      "finished epoch 1 step 305\n",
      "[]\n",
      "finished epoch 1 step 306\n",
      "[]\n",
      "finished epoch 1 step 307\n",
      "[]\n",
      "finished epoch 1 step 308\n",
      "[]\n",
      "finished epoch 1 step 309\n",
      "[]\n",
      "finished epoch 1 step 310\n",
      "[]\n",
      "finished epoch 1 step 311\n",
      "[]\n",
      "finished epoch 1 step 312\n",
      "[]\n",
      "finished epoch 1 step 313\n",
      "[]\n",
      "finished epoch 1 step 314\n",
      "[]\n",
      "finished epoch 1 step 315\n",
      "[]\n",
      "finished epoch 1 step 316\n",
      "[]\n",
      "finished epoch 1 step 317\n",
      "[]\n",
      "finished epoch 1 step 318\n",
      "[]\n",
      "finished epoch 1 step 319\n",
      "[]\n",
      "finished epoch 1 step 320\n",
      "[]\n",
      "finished epoch 1 step 321\n",
      "[]\n",
      "finished epoch 1 step 322\n",
      "[]\n",
      "finished epoch 1 step 323\n",
      "[]\n",
      "finished epoch 1 step 324\n",
      "[]\n",
      "finished epoch 1 step 325\n",
      "[]\n",
      "finished epoch 1 step 326\n",
      "[]\n",
      "finished epoch 1 step 327\n",
      "[]\n",
      "finished epoch 1 step 328\n",
      "[]\n",
      "finished epoch 1 step 329\n",
      "[]\n",
      "finished epoch 1 step 330\n",
      "[]\n",
      "finished epoch 1 step 331\n",
      "[]\n",
      "finished epoch 1 step 332\n",
      "[]\n",
      "finished epoch 1 step 333\n",
      "[]\n",
      "finished epoch 1 step 334\n",
      "[]\n",
      "finished epoch 1 step 335\n",
      "[]\n",
      "finished epoch 1 step 336\n",
      "[]\n",
      "finished epoch 1 step 337\n",
      "[]\n",
      "finished epoch 1 step 338\n",
      "[]\n",
      "finished epoch 1 step 339\n",
      "[]\n",
      "finished epoch 1 step 340\n",
      "[]\n",
      "finished epoch 1 step 341\n",
      "[]\n",
      "finished epoch 1 step 342\n",
      "[]\n",
      "finished epoch 1 step 343\n",
      "[]\n",
      "finished epoch 1 step 344\n",
      "[]\n",
      "finished epoch 1 step 345\n",
      "[]\n",
      "finished epoch 1 step 346\n",
      "[]\n",
      "finished epoch 1 step 347\n",
      "[]\n",
      "finished epoch 1 step 348\n",
      "[]\n",
      "finished epoch 1 step 349\n",
      "[]\n",
      "finished epoch 1 step 350\n",
      "[]\n",
      "finished epoch 1 step 351\n",
      "[]\n",
      "finished epoch 1 step 352\n",
      "[]\n",
      "finished epoch 1 step 353\n",
      "[]\n",
      "finished epoch 1 step 354\n",
      "[]\n",
      "finished epoch 1 step 355\n",
      "[]\n",
      "finished epoch 1 step 356\n",
      "[]\n",
      "finished epoch 1 step 357\n",
      "[]\n",
      "finished epoch 1 step 358\n",
      "[]\n",
      "finished epoch 1 step 359\n",
      "[]\n",
      "finished epoch 1 step 360\n",
      "[]\n",
      "finished epoch 1 step 361\n",
      "[]\n",
      "finished epoch 1 step 362\n",
      "[]\n",
      "finished epoch 1 step 363\n",
      "[]\n",
      "finished epoch 1 step 364\n",
      "[]\n",
      "finished epoch 2 step 365\n",
      "[]\n",
      "finished epoch 2 step 366\n",
      "[]\n",
      "finished epoch 2 step 367\n",
      "[]\n",
      "finished epoch 2 step 368\n",
      "[]\n",
      "finished epoch 2 step 369\n",
      "[]\n",
      "finished epoch 2 step 370\n",
      "[]\n",
      "finished epoch 2 step 371\n",
      "[]\n",
      "finished epoch 2 step 372\n",
      "[]\n",
      "finished epoch 2 step 373\n",
      "[]\n",
      "finished epoch 2 step 374\n",
      "[]\n",
      "finished epoch 2 step 375\n",
      "[]\n",
      "finished epoch 2 step 376\n",
      "[]\n",
      "finished epoch 2 step 377\n",
      "[]\n",
      "finished epoch 2 step 378\n",
      "[]\n",
      "finished epoch 2 step 379\n",
      "[]\n",
      "finished epoch 2 step 380\n",
      "[]\n",
      "finished epoch 2 step 381\n",
      "[]\n",
      "finished epoch 2 step 382\n",
      "[]\n",
      "finished epoch 2 step 383\n",
      "[]\n",
      "finished epoch 2 step 384\n",
      "[]\n",
      "finished epoch 2 step 385\n",
      "[]\n",
      "finished epoch 2 step 386\n",
      "[]\n",
      "finished epoch 2 step 387\n",
      "[]\n",
      "finished epoch 2 step 388\n",
      "[]\n",
      "finished epoch 2 step 389\n",
      "[]\n",
      "finished epoch 2 step 390\n",
      "[]\n",
      "finished epoch 2 step 391\n",
      "[]\n",
      "finished epoch 2 step 392\n",
      "[]\n",
      "finished epoch 2 step 393\n",
      "[]\n",
      "finished epoch 2 step 394\n",
      "[]\n",
      "finished epoch 2 step 395\n",
      "[]\n",
      "finished epoch 2 step 396\n",
      "[]\n",
      "finished epoch 2 step 397\n",
      "[]\n",
      "finished epoch 2 step 398\n",
      "[]\n",
      "finished epoch 2 step 399\n",
      "[]\n",
      "finished epoch 2 step 400\n",
      "Epoch: 3/6..  Training Loss: 0.041..  Validation Loss: 0.096..  Validation Accuracy: 0.965\n",
      "[]\n",
      "finished epoch 2 step 401\n",
      "[]\n",
      "finished epoch 2 step 402\n",
      "[]\n",
      "finished epoch 2 step 403\n",
      "[]\n",
      "finished epoch 2 step 404\n",
      "[]\n",
      "finished epoch 2 step 405\n",
      "[]\n",
      "finished epoch 2 step 406\n",
      "[]\n",
      "finished epoch 2 step 407\n",
      "[]\n",
      "finished epoch 2 step 408\n",
      "[]\n",
      "finished epoch 2 step 409\n",
      "[]\n",
      "finished epoch 2 step 410\n",
      "[]\n",
      "finished epoch 2 step 411\n",
      "[]\n",
      "finished epoch 2 step 412\n",
      "[]\n",
      "finished epoch 2 step 413\n",
      "[]\n",
      "finished epoch 2 step 414\n",
      "[]\n",
      "finished epoch 2 step 415\n",
      "[]\n",
      "finished epoch 2 step 416\n",
      "[]\n",
      "finished epoch 2 step 417\n",
      "[]\n",
      "finished epoch 2 step 418\n",
      "[]\n",
      "finished epoch 2 step 419\n",
      "[]\n",
      "finished epoch 2 step 420\n",
      "[]\n",
      "finished epoch 2 step 421\n",
      "[]\n",
      "finished epoch 2 step 422\n",
      "[]\n",
      "finished epoch 2 step 423\n",
      "[]\n",
      "finished epoch 2 step 424\n",
      "[]\n",
      "finished epoch 2 step 425\n",
      "[]\n",
      "finished epoch 2 step 426\n",
      "[]\n",
      "finished epoch 2 step 427\n",
      "[]\n",
      "finished epoch 2 step 428\n",
      "[]\n",
      "finished epoch 2 step 429\n",
      "[]\n",
      "finished epoch 2 step 430\n",
      "[]\n",
      "finished epoch 2 step 431\n",
      "[]\n",
      "finished epoch 2 step 432\n",
      "[]\n",
      "finished epoch 2 step 433\n",
      "[]\n",
      "finished epoch 2 step 434\n",
      "[]\n",
      "finished epoch 2 step 435\n",
      "[]\n",
      "finished epoch 2 step 436\n",
      "[]\n",
      "finished epoch 2 step 437\n",
      "[]\n",
      "finished epoch 2 step 438\n",
      "[]\n",
      "finished epoch 2 step 439\n",
      "[]\n",
      "finished epoch 2 step 440\n",
      "[]\n",
      "finished epoch 2 step 441\n",
      "[]\n",
      "finished epoch 2 step 442\n",
      "[]\n",
      "finished epoch 2 step 443\n",
      "[]\n",
      "finished epoch 2 step 444\n",
      "[]\n",
      "finished epoch 2 step 445\n",
      "[]\n",
      "finished epoch 2 step 446\n",
      "[]\n",
      "finished epoch 2 step 447\n",
      "[]\n",
      "finished epoch 2 step 448\n",
      "[]\n",
      "finished epoch 2 step 449\n",
      "[]\n",
      "finished epoch 2 step 450\n",
      "[]\n",
      "finished epoch 2 step 451\n",
      "[]\n",
      "finished epoch 2 step 452\n",
      "[]\n",
      "finished epoch 2 step 453\n",
      "[]\n",
      "finished epoch 2 step 454\n",
      "[]\n",
      "finished epoch 2 step 455\n",
      "[]\n",
      "finished epoch 2 step 456\n",
      "[]\n",
      "finished epoch 2 step 457\n",
      "[]\n",
      "finished epoch 2 step 458\n",
      "[]\n",
      "finished epoch 2 step 459\n",
      "[]\n",
      "finished epoch 2 step 460\n",
      "[]\n",
      "finished epoch 2 step 461\n",
      "[]\n",
      "finished epoch 2 step 462\n",
      "[]\n",
      "finished epoch 2 step 463\n",
      "[]\n",
      "finished epoch 2 step 464\n",
      "[]\n",
      "finished epoch 2 step 465\n",
      "[]\n",
      "finished epoch 2 step 466\n",
      "[]\n",
      "finished epoch 2 step 467\n",
      "[]\n",
      "finished epoch 2 step 468\n",
      "[]\n",
      "finished epoch 2 step 469\n",
      "[]\n",
      "finished epoch 2 step 470\n",
      "[]\n",
      "finished epoch 2 step 471\n",
      "[]\n",
      "finished epoch 2 step 472\n",
      "[]\n",
      "finished epoch 2 step 473\n",
      "[]\n",
      "finished epoch 2 step 474\n",
      "[]\n",
      "finished epoch 2 step 475\n",
      "[]\n",
      "finished epoch 2 step 476\n",
      "[]\n",
      "finished epoch 2 step 477\n",
      "[]\n",
      "finished epoch 2 step 478\n",
      "[]\n",
      "finished epoch 2 step 479\n",
      "[]\n",
      "finished epoch 2 step 480\n",
      "[]\n",
      "finished epoch 2 step 481\n",
      "[]\n",
      "finished epoch 2 step 482\n",
      "[]\n",
      "finished epoch 2 step 483\n",
      "[]\n",
      "finished epoch 2 step 484\n",
      "[]\n",
      "finished epoch 2 step 485\n",
      "[]\n",
      "finished epoch 2 step 486\n",
      "[]\n",
      "finished epoch 2 step 487\n",
      "[]\n",
      "finished epoch 2 step 488\n",
      "[]\n",
      "finished epoch 2 step 489\n",
      "[]\n",
      "finished epoch 2 step 490\n",
      "[]\n",
      "finished epoch 2 step 491\n",
      "[]\n",
      "finished epoch 2 step 492\n",
      "[]\n",
      "finished epoch 2 step 493\n",
      "[]\n",
      "finished epoch 2 step 494\n",
      "[]\n",
      "finished epoch 2 step 495\n",
      "[]\n",
      "finished epoch 2 step 496\n",
      "[]\n",
      "finished epoch 2 step 497\n",
      "[]\n",
      "finished epoch 2 step 498\n",
      "[]\n",
      "finished epoch 2 step 499\n",
      "[]\n",
      "finished epoch 2 step 500\n",
      "Epoch: 3/6..  Training Loss: 0.101..  Validation Loss: 0.114..  Validation Accuracy: 0.963\n",
      "[]\n",
      "finished epoch 2 step 501\n",
      "[]\n",
      "finished epoch 2 step 502\n",
      "[]\n",
      "finished epoch 2 step 503\n",
      "[]\n",
      "finished epoch 2 step 504\n",
      "[]\n",
      "finished epoch 2 step 505\n",
      "[]\n",
      "finished epoch 2 step 506\n",
      "[]\n",
      "finished epoch 2 step 507\n",
      "[]\n",
      "finished epoch 2 step 508\n",
      "[]\n",
      "finished epoch 2 step 509\n",
      "[]\n",
      "finished epoch 2 step 510\n",
      "[]\n",
      "finished epoch 2 step 511\n",
      "[]\n",
      "finished epoch 2 step 512\n",
      "[]\n",
      "finished epoch 2 step 513\n",
      "[]\n",
      "finished epoch 2 step 514\n",
      "[]\n",
      "finished epoch 2 step 515\n",
      "[]\n",
      "finished epoch 2 step 516\n",
      "[]\n",
      "finished epoch 2 step 517\n",
      "[]\n",
      "finished epoch 2 step 518\n",
      "[]\n",
      "finished epoch 2 step 519\n",
      "[]\n",
      "finished epoch 2 step 520\n",
      "[]\n",
      "finished epoch 2 step 521\n",
      "[]\n",
      "finished epoch 2 step 522\n",
      "[]\n",
      "finished epoch 2 step 523\n",
      "[]\n",
      "finished epoch 2 step 524\n",
      "[]\n",
      "finished epoch 2 step 525\n",
      "[]\n",
      "finished epoch 2 step 526\n",
      "[]\n",
      "finished epoch 2 step 527\n",
      "[]\n",
      "finished epoch 2 step 528\n",
      "[]\n",
      "finished epoch 2 step 529\n",
      "[]\n",
      "finished epoch 2 step 530\n",
      "[]\n",
      "finished epoch 2 step 531\n",
      "[]\n",
      "finished epoch 2 step 532\n",
      "[]\n",
      "finished epoch 2 step 533\n",
      "[]\n",
      "finished epoch 2 step 534\n",
      "[]\n",
      "finished epoch 2 step 535\n",
      "[]\n",
      "finished epoch 2 step 536\n",
      "[]\n",
      "finished epoch 2 step 537\n",
      "[]\n",
      "finished epoch 2 step 538\n",
      "[]\n",
      "finished epoch 2 step 539\n",
      "[]\n",
      "finished epoch 2 step 540\n",
      "[]\n",
      "finished epoch 2 step 541\n",
      "[]\n",
      "finished epoch 2 step 542\n",
      "[]\n",
      "finished epoch 2 step 543\n",
      "[]\n",
      "finished epoch 2 step 544\n",
      "[]\n",
      "finished epoch 2 step 545\n",
      "[]\n",
      "finished epoch 2 step 546\n",
      "[]\n",
      "finished epoch 3 step 547\n",
      "[]\n",
      "finished epoch 3 step 548\n",
      "[]\n",
      "finished epoch 3 step 549\n",
      "[]\n",
      "finished epoch 3 step 550\n",
      "[]\n",
      "finished epoch 3 step 551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "finished epoch 3 step 552\n",
      "[]\n",
      "finished epoch 3 step 553\n",
      "[]\n",
      "finished epoch 3 step 554\n",
      "[]\n",
      "finished epoch 3 step 555\n",
      "[]\n",
      "finished epoch 3 step 556\n",
      "[]\n",
      "finished epoch 3 step 557\n",
      "[]\n",
      "finished epoch 3 step 558\n",
      "[]\n",
      "finished epoch 3 step 559\n",
      "[]\n",
      "finished epoch 3 step 560\n",
      "[]\n",
      "finished epoch 3 step 561\n",
      "[]\n",
      "finished epoch 3 step 562\n",
      "[]\n",
      "finished epoch 3 step 563\n",
      "[]\n",
      "finished epoch 3 step 564\n",
      "[]\n",
      "finished epoch 3 step 565\n",
      "[]\n",
      "finished epoch 3 step 566\n",
      "[]\n",
      "finished epoch 3 step 567\n",
      "[]\n",
      "finished epoch 3 step 568\n",
      "[]\n",
      "finished epoch 3 step 569\n",
      "[]\n",
      "finished epoch 3 step 570\n",
      "[]\n",
      "finished epoch 3 step 571\n",
      "[]\n",
      "finished epoch 3 step 572\n",
      "[]\n",
      "finished epoch 3 step 573\n",
      "[]\n",
      "finished epoch 3 step 574\n",
      "[]\n",
      "finished epoch 3 step 575\n",
      "[]\n",
      "finished epoch 3 step 576\n",
      "[]\n",
      "finished epoch 3 step 577\n",
      "[]\n",
      "finished epoch 3 step 578\n",
      "[]\n",
      "finished epoch 3 step 579\n",
      "[]\n",
      "finished epoch 3 step 580\n",
      "[]\n",
      "finished epoch 3 step 581\n",
      "[]\n",
      "finished epoch 3 step 582\n",
      "[]\n",
      "finished epoch 3 step 583\n",
      "[]\n",
      "finished epoch 3 step 584\n",
      "[]\n",
      "finished epoch 3 step 585\n",
      "[]\n",
      "finished epoch 3 step 586\n",
      "[]\n",
      "finished epoch 3 step 587\n",
      "[]\n",
      "finished epoch 3 step 588\n",
      "[]\n",
      "finished epoch 3 step 589\n",
      "[]\n",
      "finished epoch 3 step 590\n",
      "[]\n",
      "finished epoch 3 step 591\n",
      "[]\n",
      "finished epoch 3 step 592\n",
      "[]\n",
      "finished epoch 3 step 593\n",
      "[]\n",
      "finished epoch 3 step 594\n",
      "[]\n",
      "finished epoch 3 step 595\n",
      "[]\n",
      "finished epoch 3 step 596\n",
      "[]\n",
      "finished epoch 3 step 597\n",
      "[]\n",
      "finished epoch 3 step 598\n",
      "[]\n",
      "finished epoch 3 step 599\n",
      "[]\n",
      "finished epoch 3 step 600\n",
      "Epoch: 4/6..  Training Loss: 0.055..  Validation Loss: 0.085..  Validation Accuracy: 0.969\n",
      "[]\n",
      "finished epoch 3 step 601\n",
      "[]\n",
      "finished epoch 3 step 602\n",
      "[]\n",
      "finished epoch 3 step 603\n",
      "[]\n",
      "finished epoch 3 step 604\n",
      "[]\n",
      "finished epoch 3 step 605\n",
      "[]\n",
      "finished epoch 3 step 606\n",
      "[]\n",
      "finished epoch 3 step 607\n",
      "[]\n",
      "finished epoch 3 step 608\n",
      "[]\n",
      "finished epoch 3 step 609\n",
      "[]\n",
      "finished epoch 3 step 610\n",
      "[]\n",
      "finished epoch 3 step 611\n",
      "[]\n",
      "finished epoch 3 step 612\n",
      "[]\n",
      "finished epoch 3 step 613\n",
      "[]\n",
      "finished epoch 3 step 614\n",
      "[]\n",
      "finished epoch 3 step 615\n",
      "[]\n",
      "finished epoch 3 step 616\n",
      "[]\n",
      "finished epoch 3 step 617\n",
      "[]\n",
      "finished epoch 3 step 618\n",
      "[]\n",
      "finished epoch 3 step 619\n",
      "[]\n",
      "finished epoch 3 step 620\n",
      "[]\n",
      "finished epoch 3 step 621\n",
      "[]\n",
      "finished epoch 3 step 622\n",
      "[]\n",
      "finished epoch 3 step 623\n",
      "[]\n",
      "finished epoch 3 step 624\n",
      "[]\n",
      "finished epoch 3 step 625\n",
      "[]\n",
      "finished epoch 3 step 626\n",
      "[]\n",
      "finished epoch 3 step 627\n",
      "[]\n",
      "finished epoch 3 step 628\n",
      "[]\n",
      "finished epoch 3 step 629\n",
      "[]\n",
      "finished epoch 3 step 630\n",
      "[]\n",
      "finished epoch 3 step 631\n",
      "[]\n",
      "finished epoch 3 step 632\n",
      "[]\n",
      "finished epoch 3 step 633\n",
      "[]\n",
      "finished epoch 3 step 634\n",
      "[]\n",
      "finished epoch 3 step 635\n",
      "[]\n",
      "finished epoch 3 step 636\n",
      "[]\n",
      "finished epoch 3 step 637\n",
      "[]\n",
      "finished epoch 3 step 638\n",
      "[]\n",
      "finished epoch 3 step 639\n",
      "[]\n",
      "finished epoch 3 step 640\n",
      "[]\n",
      "finished epoch 3 step 641\n",
      "[]\n",
      "finished epoch 3 step 642\n",
      "[]\n",
      "finished epoch 3 step 643\n",
      "[]\n",
      "finished epoch 3 step 644\n",
      "[]\n",
      "finished epoch 3 step 645\n",
      "[]\n",
      "finished epoch 3 step 646\n",
      "[]\n",
      "finished epoch 3 step 647\n",
      "[]\n",
      "finished epoch 3 step 648\n",
      "[]\n",
      "finished epoch 3 step 649\n",
      "[]\n",
      "finished epoch 3 step 650\n",
      "[]\n",
      "finished epoch 3 step 651\n",
      "[]\n",
      "finished epoch 3 step 652\n",
      "[]\n",
      "finished epoch 3 step 653\n",
      "[]\n",
      "finished epoch 3 step 654\n",
      "[]\n",
      "finished epoch 3 step 655\n",
      "[]\n",
      "finished epoch 3 step 656\n",
      "[]\n",
      "finished epoch 3 step 657\n",
      "[]\n",
      "finished epoch 3 step 658\n",
      "[]\n",
      "finished epoch 3 step 659\n",
      "[]\n",
      "finished epoch 3 step 660\n",
      "[]\n",
      "finished epoch 3 step 661\n",
      "[]\n",
      "finished epoch 3 step 662\n",
      "[]\n",
      "finished epoch 3 step 663\n",
      "[]\n",
      "finished epoch 3 step 664\n",
      "[]\n",
      "finished epoch 3 step 665\n",
      "[]\n",
      "finished epoch 3 step 666\n",
      "[]\n",
      "finished epoch 3 step 667\n",
      "[]\n",
      "finished epoch 3 step 668\n",
      "[]\n",
      "finished epoch 3 step 669\n",
      "[]\n",
      "finished epoch 3 step 670\n",
      "[]\n",
      "finished epoch 3 step 671\n",
      "[]\n",
      "finished epoch 3 step 672\n",
      "[]\n",
      "finished epoch 3 step 673\n",
      "[]\n",
      "finished epoch 3 step 674\n",
      "[]\n",
      "finished epoch 3 step 675\n",
      "[]\n",
      "finished epoch 3 step 676\n",
      "[]\n",
      "finished epoch 3 step 677\n",
      "[]\n",
      "finished epoch 3 step 678\n",
      "[]\n",
      "finished epoch 3 step 679\n",
      "[]\n",
      "finished epoch 3 step 680\n",
      "[]\n",
      "finished epoch 3 step 681\n",
      "[]\n",
      "finished epoch 3 step 682\n",
      "[]\n",
      "finished epoch 3 step 683\n",
      "[]\n",
      "finished epoch 3 step 684\n",
      "[]\n",
      "finished epoch 3 step 685\n",
      "[]\n",
      "finished epoch 3 step 686\n",
      "[]\n",
      "finished epoch 3 step 687\n",
      "[]\n",
      "finished epoch 3 step 688\n",
      "[]\n",
      "finished epoch 3 step 689\n",
      "[]\n",
      "finished epoch 3 step 690\n",
      "[]\n",
      "finished epoch 3 step 691\n",
      "[]\n",
      "finished epoch 3 step 692\n",
      "[]\n",
      "finished epoch 3 step 693\n",
      "[]\n",
      "finished epoch 3 step 694\n",
      "[]\n",
      "finished epoch 3 step 695\n",
      "[]\n",
      "finished epoch 3 step 696\n",
      "[]\n",
      "finished epoch 3 step 697\n",
      "[]\n",
      "finished epoch 3 step 698\n",
      "[]\n",
      "finished epoch 3 step 699\n",
      "[]\n",
      "finished epoch 3 step 700\n",
      "Epoch: 4/6..  Training Loss: 0.102..  Validation Loss: 0.079..  Validation Accuracy: 0.976\n",
      "[]\n",
      "finished epoch 3 step 701\n",
      "[]\n",
      "finished epoch 3 step 702\n",
      "[]\n",
      "finished epoch 3 step 703\n",
      "[]\n",
      "finished epoch 3 step 704\n",
      "[]\n",
      "finished epoch 3 step 705\n",
      "[]\n",
      "finished epoch 3 step 706\n",
      "[]\n",
      "finished epoch 3 step 707\n",
      "[]\n",
      "finished epoch 3 step 708\n",
      "[]\n",
      "finished epoch 3 step 709\n",
      "[]\n",
      "finished epoch 3 step 710\n",
      "[]\n",
      "finished epoch 3 step 711\n",
      "[]\n",
      "finished epoch 3 step 712\n",
      "[]\n",
      "finished epoch 3 step 713\n",
      "[]\n",
      "finished epoch 3 step 714\n",
      "[]\n",
      "finished epoch 3 step 715\n",
      "[]\n",
      "finished epoch 3 step 716\n",
      "[]\n",
      "finished epoch 3 step 717\n",
      "[]\n",
      "finished epoch 3 step 718\n",
      "[]\n",
      "finished epoch 3 step 719\n",
      "[]\n",
      "finished epoch 3 step 720\n",
      "[]\n",
      "finished epoch 3 step 721\n",
      "[]\n",
      "finished epoch 3 step 722\n",
      "[]\n",
      "finished epoch 3 step 723\n",
      "[]\n",
      "finished epoch 3 step 724\n",
      "[]\n",
      "finished epoch 3 step 725\n",
      "[]\n",
      "finished epoch 3 step 726\n",
      "[]\n",
      "finished epoch 3 step 727\n",
      "[]\n",
      "finished epoch 3 step 728\n",
      "[]\n",
      "finished epoch 4 step 729\n",
      "[]\n",
      "finished epoch 4 step 730\n",
      "[]\n",
      "finished epoch 4 step 731\n",
      "[]\n",
      "finished epoch 4 step 732\n",
      "[]\n",
      "finished epoch 4 step 733\n",
      "[]\n",
      "finished epoch 4 step 734\n",
      "[]\n",
      "finished epoch 4 step 735\n",
      "[]\n",
      "finished epoch 4 step 736\n",
      "[]\n",
      "finished epoch 4 step 737\n",
      "[]\n",
      "finished epoch 4 step 738\n",
      "[]\n",
      "finished epoch 4 step 739\n",
      "[]\n",
      "finished epoch 4 step 740\n",
      "[]\n",
      "finished epoch 4 step 741\n",
      "[]\n",
      "finished epoch 4 step 742\n",
      "[]\n",
      "finished epoch 4 step 743\n",
      "[]\n",
      "finished epoch 4 step 744\n",
      "[]\n",
      "finished epoch 4 step 745\n",
      "[]\n",
      "finished epoch 4 step 746\n",
      "[]\n",
      "finished epoch 4 step 747\n",
      "[]\n",
      "finished epoch 4 step 748\n",
      "[]\n",
      "finished epoch 4 step 749\n",
      "[]\n",
      "finished epoch 4 step 750\n",
      "[]\n",
      "finished epoch 4 step 751\n",
      "[]\n",
      "finished epoch 4 step 752\n",
      "[]\n",
      "finished epoch 4 step 753\n",
      "[]\n",
      "finished epoch 4 step 754\n",
      "[]\n",
      "finished epoch 4 step 755\n",
      "[]\n",
      "finished epoch 4 step 756\n",
      "[]\n",
      "finished epoch 4 step 757\n",
      "[]\n",
      "finished epoch 4 step 758\n",
      "[]\n",
      "finished epoch 4 step 759\n",
      "[]\n",
      "finished epoch 4 step 760\n",
      "[]\n",
      "finished epoch 4 step 761\n",
      "[]\n",
      "finished epoch 4 step 762\n",
      "[]\n",
      "finished epoch 4 step 763\n",
      "[]\n",
      "finished epoch 4 step 764\n",
      "[]\n",
      "finished epoch 4 step 765\n",
      "[]\n",
      "finished epoch 4 step 766\n",
      "[]\n",
      "finished epoch 4 step 767\n",
      "[]\n",
      "finished epoch 4 step 768\n",
      "[]\n",
      "finished epoch 4 step 769\n",
      "[]\n",
      "finished epoch 4 step 770\n",
      "[]\n",
      "finished epoch 4 step 771\n",
      "[]\n",
      "finished epoch 4 step 772\n",
      "[]\n",
      "finished epoch 4 step 773\n",
      "[]\n",
      "finished epoch 4 step 774\n",
      "[]\n",
      "finished epoch 4 step 775\n",
      "[]\n",
      "finished epoch 4 step 776\n",
      "[]\n",
      "finished epoch 4 step 777\n",
      "[]\n",
      "finished epoch 4 step 778\n",
      "[]\n",
      "finished epoch 4 step 779\n",
      "[]\n",
      "finished epoch 4 step 780\n",
      "[]\n",
      "finished epoch 4 step 781\n",
      "[]\n",
      "finished epoch 4 step 782\n",
      "[]\n",
      "finished epoch 4 step 783\n",
      "[]\n",
      "finished epoch 4 step 784\n",
      "[]\n",
      "finished epoch 4 step 785\n",
      "[]\n",
      "finished epoch 4 step 786\n",
      "[]\n",
      "finished epoch 4 step 787\n",
      "[]\n",
      "finished epoch 4 step 788\n",
      "[]\n",
      "finished epoch 4 step 789\n",
      "[]\n",
      "finished epoch 4 step 790\n",
      "[]\n",
      "finished epoch 4 step 791\n",
      "[]\n",
      "finished epoch 4 step 792\n",
      "[]\n",
      "finished epoch 4 step 793\n",
      "[]\n",
      "finished epoch 4 step 794\n",
      "[]\n",
      "finished epoch 4 step 795\n",
      "[]\n",
      "finished epoch 4 step 796\n",
      "[]\n",
      "finished epoch 4 step 797\n",
      "[]\n",
      "finished epoch 4 step 798\n",
      "[]\n",
      "finished epoch 4 step 799\n",
      "[]\n",
      "finished epoch 4 step 800\n",
      "Epoch: 5/6..  Training Loss: 0.075..  Validation Loss: 0.079..  Validation Accuracy: 0.974\n",
      "[]\n",
      "finished epoch 4 step 801\n",
      "[]\n",
      "finished epoch 4 step 802\n",
      "[]\n",
      "finished epoch 4 step 803\n",
      "[]\n",
      "finished epoch 4 step 804\n",
      "[]\n",
      "finished epoch 4 step 805\n",
      "[]\n",
      "finished epoch 4 step 806\n",
      "[]\n",
      "finished epoch 4 step 807\n",
      "[]\n",
      "finished epoch 4 step 808\n",
      "[]\n",
      "finished epoch 4 step 809\n",
      "[]\n",
      "finished epoch 4 step 810\n",
      "[]\n",
      "finished epoch 4 step 811\n",
      "[]\n",
      "finished epoch 4 step 812\n",
      "[]\n",
      "finished epoch 4 step 813\n",
      "[]\n",
      "finished epoch 4 step 814\n",
      "[]\n",
      "finished epoch 4 step 815\n",
      "[]\n",
      "finished epoch 4 step 816\n",
      "[]\n",
      "finished epoch 4 step 817\n",
      "[]\n",
      "finished epoch 4 step 818\n",
      "[]\n",
      "finished epoch 4 step 819\n",
      "[]\n",
      "finished epoch 4 step 820\n",
      "[]\n",
      "finished epoch 4 step 821\n",
      "[]\n",
      "finished epoch 4 step 822\n",
      "[]\n",
      "finished epoch 4 step 823\n",
      "[]\n",
      "finished epoch 4 step 824\n",
      "[]\n",
      "finished epoch 4 step 825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "finished epoch 4 step 826\n",
      "[]\n",
      "finished epoch 4 step 827\n",
      "[]\n",
      "finished epoch 4 step 828\n",
      "[]\n",
      "finished epoch 4 step 829\n",
      "[]\n",
      "finished epoch 4 step 830\n",
      "[]\n",
      "finished epoch 4 step 831\n",
      "[]\n",
      "finished epoch 4 step 832\n",
      "[]\n",
      "finished epoch 4 step 833\n",
      "[]\n",
      "finished epoch 4 step 834\n",
      "[]\n",
      "finished epoch 4 step 835\n",
      "[]\n",
      "finished epoch 4 step 836\n",
      "[]\n",
      "finished epoch 4 step 837\n",
      "[]\n",
      "finished epoch 4 step 838\n",
      "[]\n",
      "finished epoch 4 step 839\n",
      "[]\n",
      "finished epoch 4 step 840\n",
      "[]\n",
      "finished epoch 4 step 841\n",
      "[]\n",
      "finished epoch 4 step 842\n",
      "[]\n",
      "finished epoch 4 step 843\n",
      "[]\n",
      "finished epoch 4 step 844\n",
      "[]\n",
      "finished epoch 4 step 845\n",
      "[]\n",
      "finished epoch 4 step 846\n",
      "[]\n",
      "finished epoch 4 step 847\n",
      "[]\n",
      "finished epoch 4 step 848\n",
      "[]\n",
      "finished epoch 4 step 849\n",
      "[]\n",
      "finished epoch 4 step 850\n",
      "[]\n",
      "finished epoch 4 step 851\n",
      "[]\n",
      "finished epoch 4 step 852\n",
      "[]\n",
      "finished epoch 4 step 853\n",
      "[]\n",
      "finished epoch 4 step 854\n",
      "[]\n",
      "finished epoch 4 step 855\n",
      "[]\n",
      "finished epoch 4 step 856\n",
      "[]\n",
      "finished epoch 4 step 857\n",
      "[]\n",
      "finished epoch 4 step 858\n",
      "[]\n",
      "finished epoch 4 step 859\n",
      "[]\n",
      "finished epoch 4 step 860\n",
      "[]\n",
      "finished epoch 4 step 861\n",
      "[]\n",
      "finished epoch 4 step 862\n",
      "[]\n",
      "finished epoch 4 step 863\n",
      "[]\n",
      "finished epoch 4 step 864\n",
      "[]\n",
      "finished epoch 4 step 865\n",
      "[]\n",
      "finished epoch 4 step 866\n",
      "[]\n",
      "finished epoch 4 step 867\n",
      "[]\n",
      "finished epoch 4 step 868\n",
      "[]\n",
      "finished epoch 4 step 869\n",
      "[]\n",
      "finished epoch 4 step 870\n",
      "[]\n",
      "finished epoch 4 step 871\n",
      "[]\n",
      "finished epoch 4 step 872\n",
      "[]\n",
      "finished epoch 4 step 873\n",
      "[]\n",
      "finished epoch 4 step 874\n",
      "[]\n",
      "finished epoch 4 step 875\n",
      "[]\n",
      "finished epoch 4 step 876\n",
      "[]\n",
      "finished epoch 4 step 877\n",
      "[]\n",
      "finished epoch 4 step 878\n",
      "[]\n",
      "finished epoch 4 step 879\n",
      "[]\n",
      "finished epoch 4 step 880\n",
      "[]\n",
      "finished epoch 4 step 881\n",
      "[]\n",
      "finished epoch 4 step 882\n",
      "[]\n",
      "finished epoch 4 step 883\n",
      "[]\n",
      "finished epoch 4 step 884\n",
      "[]\n",
      "finished epoch 4 step 885\n",
      "[]\n",
      "finished epoch 4 step 886\n",
      "[]\n",
      "finished epoch 4 step 887\n",
      "[]\n",
      "finished epoch 4 step 888\n",
      "[]\n",
      "finished epoch 4 step 889\n",
      "[]\n",
      "finished epoch 4 step 890\n",
      "[]\n",
      "finished epoch 4 step 891\n",
      "[]\n",
      "finished epoch 4 step 892\n",
      "[]\n",
      "finished epoch 4 step 893\n",
      "[]\n",
      "finished epoch 4 step 894\n",
      "[]\n",
      "finished epoch 4 step 895\n",
      "[]\n",
      "finished epoch 4 step 896\n",
      "[]\n",
      "finished epoch 4 step 897\n",
      "[]\n",
      "finished epoch 4 step 898\n",
      "[]\n",
      "finished epoch 4 step 899\n",
      "[]\n",
      "finished epoch 4 step 900\n",
      "Epoch: 5/6..  Training Loss: 0.095..  Validation Loss: 0.083..  Validation Accuracy: 0.974\n",
      "[]\n",
      "finished epoch 4 step 901\n",
      "[]\n",
      "finished epoch 4 step 902\n",
      "[]\n",
      "finished epoch 4 step 903\n",
      "[]\n",
      "finished epoch 4 step 904\n",
      "[]\n",
      "finished epoch 4 step 905\n",
      "[]\n",
      "finished epoch 4 step 906\n",
      "[]\n",
      "finished epoch 4 step 907\n",
      "[]\n",
      "finished epoch 4 step 908\n",
      "[]\n",
      "finished epoch 4 step 909\n",
      "[]\n",
      "finished epoch 4 step 910\n",
      "[]\n",
      "finished epoch 5 step 911\n",
      "[]\n",
      "finished epoch 5 step 912\n",
      "[]\n",
      "finished epoch 5 step 913\n",
      "[]\n",
      "finished epoch 5 step 914\n",
      "[]\n",
      "finished epoch 5 step 915\n",
      "[]\n",
      "finished epoch 5 step 916\n",
      "[]\n",
      "finished epoch 5 step 917\n",
      "[]\n",
      "finished epoch 5 step 918\n",
      "[]\n",
      "finished epoch 5 step 919\n",
      "[]\n",
      "finished epoch 5 step 920\n",
      "[]\n",
      "finished epoch 5 step 921\n",
      "[]\n",
      "finished epoch 5 step 922\n",
      "[]\n",
      "finished epoch 5 step 923\n",
      "[]\n",
      "finished epoch 5 step 924\n",
      "[]\n",
      "finished epoch 5 step 925\n",
      "[]\n",
      "finished epoch 5 step 926\n",
      "[]\n",
      "finished epoch 5 step 927\n",
      "[]\n",
      "finished epoch 5 step 928\n",
      "[]\n",
      "finished epoch 5 step 929\n",
      "[]\n",
      "finished epoch 5 step 930\n",
      "[]\n",
      "finished epoch 5 step 931\n",
      "[]\n",
      "finished epoch 5 step 932\n",
      "[]\n",
      "finished epoch 5 step 933\n",
      "[]\n",
      "finished epoch 5 step 934\n",
      "[]\n",
      "finished epoch 5 step 935\n",
      "[]\n",
      "finished epoch 5 step 936\n",
      "[]\n",
      "finished epoch 5 step 937\n",
      "[]\n",
      "finished epoch 5 step 938\n",
      "[]\n",
      "finished epoch 5 step 939\n",
      "[]\n",
      "finished epoch 5 step 940\n",
      "[]\n",
      "finished epoch 5 step 941\n",
      "[]\n",
      "finished epoch 5 step 942\n",
      "[]\n",
      "finished epoch 5 step 943\n",
      "[]\n",
      "finished epoch 5 step 944\n",
      "[]\n",
      "finished epoch 5 step 945\n",
      "[]\n",
      "finished epoch 5 step 946\n",
      "[]\n",
      "finished epoch 5 step 947\n",
      "[]\n",
      "finished epoch 5 step 948\n",
      "[]\n",
      "finished epoch 5 step 949\n",
      "[]\n",
      "finished epoch 5 step 950\n",
      "[]\n",
      "finished epoch 5 step 951\n",
      "[]\n",
      "finished epoch 5 step 952\n",
      "[]\n",
      "finished epoch 5 step 953\n",
      "[]\n",
      "finished epoch 5 step 954\n",
      "[]\n",
      "finished epoch 5 step 955\n",
      "[]\n",
      "finished epoch 5 step 956\n",
      "[]\n",
      "finished epoch 5 step 957\n",
      "[]\n",
      "finished epoch 5 step 958\n",
      "[]\n",
      "finished epoch 5 step 959\n",
      "[]\n",
      "finished epoch 5 step 960\n",
      "[]\n",
      "finished epoch 5 step 961\n",
      "[]\n",
      "finished epoch 5 step 962\n",
      "[]\n",
      "finished epoch 5 step 963\n",
      "[]\n",
      "finished epoch 5 step 964\n",
      "[]\n",
      "finished epoch 5 step 965\n",
      "[]\n",
      "finished epoch 5 step 966\n",
      "[]\n",
      "finished epoch 5 step 967\n",
      "[]\n",
      "finished epoch 5 step 968\n",
      "[]\n",
      "finished epoch 5 step 969\n",
      "[]\n",
      "finished epoch 5 step 970\n",
      "[]\n",
      "finished epoch 5 step 971\n",
      "[]\n",
      "finished epoch 5 step 972\n",
      "[]\n",
      "finished epoch 5 step 973\n",
      "[]\n",
      "finished epoch 5 step 974\n",
      "[]\n",
      "finished epoch 5 step 975\n",
      "[]\n",
      "finished epoch 5 step 976\n",
      "[]\n",
      "finished epoch 5 step 977\n",
      "[]\n",
      "finished epoch 5 step 978\n",
      "[]\n",
      "finished epoch 5 step 979\n",
      "[]\n",
      "finished epoch 5 step 980\n",
      "[]\n",
      "finished epoch 5 step 981\n",
      "[]\n",
      "finished epoch 5 step 982\n",
      "[]\n",
      "finished epoch 5 step 983\n",
      "[]\n",
      "finished epoch 5 step 984\n",
      "[]\n",
      "finished epoch 5 step 985\n",
      "[]\n",
      "finished epoch 5 step 986\n",
      "[]\n",
      "finished epoch 5 step 987\n",
      "[]\n",
      "finished epoch 5 step 988\n",
      "[]\n",
      "finished epoch 5 step 989\n",
      "[]\n",
      "finished epoch 5 step 990\n",
      "[]\n",
      "finished epoch 5 step 991\n",
      "[]\n",
      "finished epoch 5 step 992\n",
      "[]\n",
      "finished epoch 5 step 993\n",
      "[]\n",
      "finished epoch 5 step 994\n",
      "[]\n",
      "finished epoch 5 step 995\n",
      "[]\n",
      "finished epoch 5 step 996\n",
      "[]\n",
      "finished epoch 5 step 997\n",
      "[]\n",
      "finished epoch 5 step 998\n",
      "[]\n",
      "finished epoch 5 step 999\n",
      "[]\n",
      "finished epoch 5 step 1000\n",
      "Epoch: 6/6..  Training Loss: 0.096..  Validation Loss: 0.082..  Validation Accuracy: 0.965\n",
      "[]\n",
      "finished epoch 5 step 1001\n",
      "[]\n",
      "finished epoch 5 step 1002\n",
      "[]\n",
      "finished epoch 5 step 1003\n",
      "[]\n",
      "finished epoch 5 step 1004\n",
      "[]\n",
      "finished epoch 5 step 1005\n",
      "[]\n",
      "finished epoch 5 step 1006\n",
      "[]\n",
      "finished epoch 5 step 1007\n",
      "[]\n",
      "finished epoch 5 step 1008\n",
      "[]\n",
      "finished epoch 5 step 1009\n",
      "[]\n",
      "finished epoch 5 step 1010\n",
      "[]\n",
      "finished epoch 5 step 1011\n",
      "[]\n",
      "finished epoch 5 step 1012\n",
      "[]\n",
      "finished epoch 5 step 1013\n",
      "[]\n",
      "finished epoch 5 step 1014\n",
      "[]\n",
      "finished epoch 5 step 1015\n",
      "[]\n",
      "finished epoch 5 step 1016\n",
      "[]\n",
      "finished epoch 5 step 1017\n",
      "[]\n",
      "finished epoch 5 step 1018\n",
      "[]\n",
      "finished epoch 5 step 1019\n",
      "[]\n",
      "finished epoch 5 step 1020\n",
      "[]\n",
      "finished epoch 5 step 1021\n",
      "[]\n",
      "finished epoch 5 step 1022\n",
      "[]\n",
      "finished epoch 5 step 1023\n",
      "[]\n",
      "finished epoch 5 step 1024\n",
      "[]\n",
      "finished epoch 5 step 1025\n",
      "[]\n",
      "finished epoch 5 step 1026\n",
      "[]\n",
      "finished epoch 5 step 1027\n",
      "[]\n",
      "finished epoch 5 step 1028\n",
      "[]\n",
      "finished epoch 5 step 1029\n",
      "[]\n",
      "finished epoch 5 step 1030\n",
      "[]\n",
      "finished epoch 5 step 1031\n",
      "[]\n",
      "finished epoch 5 step 1032\n",
      "[]\n",
      "finished epoch 5 step 1033\n",
      "[]\n",
      "finished epoch 5 step 1034\n",
      "[]\n",
      "finished epoch 5 step 1035\n",
      "[]\n",
      "finished epoch 5 step 1036\n",
      "[]\n",
      "finished epoch 5 step 1037\n",
      "[]\n",
      "finished epoch 5 step 1038\n",
      "[]\n",
      "finished epoch 5 step 1039\n",
      "[]\n",
      "finished epoch 5 step 1040\n",
      "[]\n",
      "finished epoch 5 step 1041\n",
      "[]\n",
      "finished epoch 5 step 1042\n",
      "[]\n",
      "finished epoch 5 step 1043\n",
      "[]\n",
      "finished epoch 5 step 1044\n",
      "[]\n",
      "finished epoch 5 step 1045\n",
      "[]\n",
      "finished epoch 5 step 1046\n",
      "[]\n",
      "finished epoch 5 step 1047\n",
      "[]\n",
      "finished epoch 5 step 1048\n",
      "[]\n",
      "finished epoch 5 step 1049\n",
      "[]\n",
      "finished epoch 5 step 1050\n",
      "[]\n",
      "finished epoch 5 step 1051\n",
      "[]\n",
      "finished epoch 5 step 1052\n",
      "[]\n",
      "finished epoch 5 step 1053\n",
      "[]\n",
      "finished epoch 5 step 1054\n",
      "[]\n",
      "finished epoch 5 step 1055\n",
      "[]\n",
      "finished epoch 5 step 1056\n",
      "[]\n",
      "finished epoch 5 step 1057\n",
      "[]\n",
      "finished epoch 5 step 1058\n",
      "[]\n",
      "finished epoch 5 step 1059\n",
      "[]\n",
      "finished epoch 5 step 1060\n",
      "[]\n",
      "finished epoch 5 step 1061\n",
      "[]\n",
      "finished epoch 5 step 1062\n",
      "[]\n",
      "finished epoch 5 step 1063\n",
      "[]\n",
      "finished epoch 5 step 1064\n",
      "[]\n",
      "finished epoch 5 step 1065\n",
      "[]\n",
      "finished epoch 5 step 1066\n",
      "[]\n",
      "finished epoch 5 step 1067\n",
      "[]\n",
      "finished epoch 5 step 1068\n",
      "[]\n",
      "finished epoch 5 step 1069\n",
      "[]\n",
      "finished epoch 5 step 1070\n",
      "[]\n",
      "finished epoch 5 step 1071\n",
      "[]\n",
      "finished epoch 5 step 1072\n",
      "[]\n",
      "finished epoch 5 step 1073\n",
      "[]\n",
      "finished epoch 5 step 1074\n",
      "[]\n",
      "finished epoch 5 step 1075\n",
      "[]\n",
      "finished epoch 5 step 1076\n",
      "[]\n",
      "finished epoch 5 step 1077\n",
      "[]\n",
      "finished epoch 5 step 1078\n",
      "[]\n",
      "finished epoch 5 step 1079\n",
      "[]\n",
      "finished epoch 5 step 1080\n",
      "[]\n",
      "finished epoch 5 step 1081\n",
      "[]\n",
      "finished epoch 5 step 1082\n",
      "[]\n",
      "finished epoch 5 step 1083\n",
      "[]\n",
      "finished epoch 5 step 1084\n",
      "[]\n",
      "finished epoch 5 step 1085\n",
      "[]\n",
      "finished epoch 5 step 1086\n",
      "[]\n",
      "finished epoch 5 step 1087\n",
      "[]\n",
      "finished epoch 5 step 1088\n",
      "[]\n",
      "finished epoch 5 step 1089\n",
      "[]\n",
      "finished epoch 5 step 1090\n",
      "[]\n",
      "finished epoch 5 step 1091\n",
      "[]\n",
      "finished epoch 5 step 1092\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the classifier\n",
    "\n",
    "#from workspace_utils import active_session\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"using {} device\".format(device))\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "def train_classifier():\n",
    "\n",
    "    #with active_session():\n",
    "\n",
    "    epochs = 6\n",
    "    steps = 0\n",
    "    print_every = 100\n",
    "\n",
    "    model.to('cuda')\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for images, labels in iter(train_loader):\n",
    "            if steps % print_every == 0:\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "                # Turn off gradients for validation, saves memory and computations\n",
    "                with torch.no_grad():\n",
    "                    validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
    "                      \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
    "                val_loss_history.append(validation_loss/len(validate_loader))\n",
    "                val_accuracy_history.append(accuracy/len(validate_loader))\n",
    "                running_loss = 0\n",
    "                model.train()\n",
    "            steps += 1\n",
    "\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "\n",
    "            #plt.plot(loss_history)\n",
    "            print(loss_history)\n",
    "\n",
    "                \n",
    "            print(f\"finished epoch {e} step {steps}\")\n",
    "            \n",
    "    plt.plot(loss_history)\n",
    "    plt.plot(val_loss_history)\n",
    "    plt.plot(val_accuracy_history)\n",
    "    \n",
    "train_classifier()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cf1817a880>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(val_loss_history, label = 'Validation Loss')\n",
    "plt.plot(val_accuracy_history, label = \"Validation Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image\n",
    "#fgsm_attack(np.array(cv2.imread('kyle.jpg')),.8,torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 0, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def test( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    model.eval()\n",
    "    # Loop over all examples in test set\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "#         if i%100 == 0:\n",
    "#             print('starting iteration', i)\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model.forward(data)\n",
    "        #|print(output)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        #print(init_pred)\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        \n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "    \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples\n",
    "\n",
    "print([np.random.randint(0,high =3) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_UH( models, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    # Loop over all examples in test set\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "#         if i%100 == 0:\n",
    "#             print('starting iteration', i)\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        model_bad = models[np.random.randint(0,high=len(models))]\n",
    "        output = model_bad.forward(data)\n",
    "        #print(output)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        #print(init_pred)\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model_bad.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = models[np.random.randint(0,high=len(models))].forward(perturbed_data)\n",
    "        \n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "    \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples\n",
    "\n",
    "print([np.random.randint(0,high =3) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epsilon: 0\tTest Accuracy = 880 / 987 = 0.8915906788247214\n",
      "0.8915906788247214\n",
      "0.2\n",
      "Epsilon: 0.2\tTest Accuracy = 809 / 987 = 0.8196555217831814\n",
      "0.8196555217831814\n",
      "0.4\n",
      "Epsilon: 0.4\tTest Accuracy = 705 / 987 = 0.7142857142857143\n",
      "0.7142857142857143\n",
      "0.6\n",
      "Epsilon: 0.6\tTest Accuracy = 683 / 987 = 0.6919959473150963\n",
      "0.6919959473150963\n",
      "0.8\n",
      "Epsilon: 0.8\tTest Accuracy = 677 / 987 = 0.6859169199594731\n",
      "0.6859169199594731\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "epsilons = [0,0.2,0.4,0.6,0.8]\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    print(eps)\n",
    "    #acc, ex = test_UH([model1,model2,model3], 'cuda', test_loader, eps)\n",
    "    acc,ex = test(model,'cuda',test_loader,eps)\n",
    "    print(acc)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = plt.subplots(1,2)\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "\n",
    "#ax1.plot(x1, y1)\n",
    "#ax2.plot(x2, y2)\n",
    "#ax1.set_title('First plot')\n",
    "#ax2.set_title('Second plot')\n",
    "plt.show()\n",
    "ax1.imshow('partykatie.jpg')\n",
    "#x[0][0].imshow('partykatie.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9747983813285828\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(model, test_loader):\n",
    "\n",
    "    # Do validation on the test set\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        accuracy = 0\n",
    "    \n",
    "        for images, labels in iter(test_loader):\n",
    "    \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            \n",
    "            output = model.forward(images)\n",
    "\n",
    "            probabilities = torch.exp(output)\n",
    "        \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
    "        \n",
    "        \n",
    "test_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_uniform_hash(models, test_loader):\n",
    "\n",
    "    # Do validation on the test set\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model.to('cuda')\n",
    "    \n",
    "    n = len(models)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        accuracy = 0\n",
    "    \n",
    "        for images, labels in iter(test_loader):\n",
    "    \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            \n",
    "            output = models[np.random.randint(0,high=n)].forward(images)\n",
    "\n",
    "            probabilities = torch.exp(output)\n",
    "        \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
    "        \n",
    "        \n",
    "test_accuracy_uniform_hash([model1,model2,model3], test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoint\n",
    "\n",
    "def save_checkpoint(model):\n",
    "\n",
    "    model.class_to_idx = training_dataset.class_to_idx\n",
    "\n",
    "    checkpoint = {'arch': \"vgg19\",\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'model_state_dict': model.state_dict()\n",
    "                 }\n",
    "\n",
    "    torch.save(checkpoint, 'model_2.pth')\n",
    "    \n",
    "save_checkpoint(model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    \n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    if checkpoint['arch'] == 'vgg19':\n",
    "        \n",
    "        model = models.vgg19(pretrained=True)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Architecture not recognized.\")\n",
    "    \n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    # Build custom classifier\n",
    "    classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 10, bias= True)),\n",
    "                                        ('tanh1', nn.Tanh()),\n",
    "                                        ('dropout', nn.Dropout(p=0.25)),\n",
    "                                        ('fc2',nn.Linear(10,2,bias=True)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "    model.classifier = classifier\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model.to(\"cuda\")\n",
    "    return model\n",
    "\n",
    "model1 = load_checkpoint('model_1.pth')\n",
    "model2 = load_checkpoint('model_2.pth')\n",
    "model3 = load_checkpoint('model_3.pth')\n",
    "model4 = load_checkpoint('model_4.pth')\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_image(image_path):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    \n",
    "    pil_image = Image.open(image_path)\n",
    "\n",
    "    \n",
    "    # Resize\n",
    "    if pil_image.size[0] > pil_image.size[1]:\n",
    "        pil_image.thumbnail((5000, 256))\n",
    "    else:\n",
    "        pil_image.thumbnail((256, 5000))\n",
    "        \n",
    "    # Crop \n",
    "    left_margin = (pil_image.width-224)/2\n",
    "    bottom_margin = (pil_image.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    \n",
    "    pil_image = pil_image.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "    \n",
    "    # Normalize\n",
    "    np_image = np.array(pil_image)[:,:,:3]/255\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "    \n",
    "    # PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array\n",
    "    # Color channel needs to be first; retain the order of the other two dimensions.\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "    \n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "image = process_image('flowers/test/nn1/image_06743.jpg')\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the code to predict the class from an image file\n",
    "import glob\n",
    "def predict(image_path, model, topk=2):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    image = process_image(image_path)\n",
    "    #print(image.shape)\n",
    "    \n",
    "    # Convert image to PyTorch tensor first\n",
    "    image = torch.from_numpy(image).type(torch.cuda.FloatTensor)\n",
    "    #print(image.shape)\n",
    "    #print(type(image))\n",
    "    \n",
    "    # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    output = model.forward(image)\n",
    "    \n",
    "    probabilities = torch.exp(output)\n",
    "    \n",
    "    # Probabilities and the indices of those probabilities corresponding to the classes\n",
    "    top_probabilities, top_indices = probabilities.topk(topk)\n",
    "    \n",
    "    # Convert to lists\n",
    "    top_probabilities = top_probabilities.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    top_indices = top_indices.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    \n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "    \n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    #print(idx_to_class)\n",
    "    \n",
    "    top_classes = [idx_to_class[index] for index in top_indices]\n",
    "    \n",
    "    return top_probabilities, top_classes\n",
    "M_i = {'1':'No Mask', '2':'Mask'}\n",
    "#nprobs,classes = predict('mask_data/test/1/image_96.png',model)\n",
    "#probs,classes = predict('mask_data/idiot.png',model)\n",
    "#probs,classes = predict('all_data/2/image_3.png',model)\n",
    "#probs,classes = predict('doctor.jpg',model)\n",
    "#probs,classes = predict('testimg.jpg',model)\n",
    "#probs,classes = predict('idiot2.png',model)\n",
    "#probs,classes = predict('doctor3.jpg',model)\n",
    "\n",
    "#probs,classes = predict('doctor4.jpg',model)\n",
    "#probs,classes = predict('doctor2.jpg',model)\n",
    "model=model1\n",
    "probs,classes = predict('aaronzhu3.png',model)\n",
    "#@probs,classes = predict('henryw.jpg',model)\n",
    "# correct = 0\n",
    "# for image in glob.glob('mask_data/test/2/*'):\n",
    "#     if predict(image,model)[1][0] == '2':\n",
    "#         correct += 1\n",
    "# print(correct/len(glob.glob('mask_data/test/2/*')))\n",
    "print(probs)\n",
    "print(classes)\n",
    "print(f\"Prediction: {M_i[classes[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the code to predict the class from an image file\n",
    "import glob\n",
    "def predict_uniform_hash(image_path, models, topk=2):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    image = process_image(image_path)\n",
    "    #print(image.shape)\n",
    "    \n",
    "    # Convert image to PyTorch tensor first\n",
    "    image = torch.from_numpy(image).type(torch.cuda.FloatTensor)\n",
    "    #print(image.shape)\n",
    "    #print(type(image))\n",
    "    \n",
    "    # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    p = np.random.randint(0,len(models))\n",
    "    \n",
    "    print(\"Using model\", p+1)\n",
    "    output = models[np.random.randint(0,len(models))].forward(image)\n",
    "    \n",
    "    probabilities = torch.exp(output)\n",
    "    \n",
    "    # Probabilities and the indices of those probabilities corresponding to the classes\n",
    "    top_probabilities, top_indices = probabilities.topk(topk)\n",
    "    \n",
    "    # Convert to lists\n",
    "    top_probabilities = top_probabilities.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    top_indices = top_indices.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    \n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "    \n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    #print(idx_to_class)\n",
    "    \n",
    "    top_classes = [idx_to_class[index] for index in top_indices]\n",
    "    \n",
    "    return top_probabilities, top_classes\n",
    "\n",
    "M_i = {'1':'No Mask', '2':'Mask'}\n",
    "#probs,classes = predict('mask_data/test/1/image_96.png',model)\n",
    "#probs,classes = predict('mask_data/idiot.png',model)\n",
    "#probs,classes = predict('all_data/2/image_3.png',model)\n",
    "probs,classes = predict_uniform_hash('idiot2.png',[model1,model2,model3])\n",
    "\n",
    "#correct = 0\n",
    "# for image in glob.glob('mask_data/test/1/*'):\n",
    "#     if predict(image,model)[1][0] == '1':\n",
    "#         correct += 1\n",
    "#print(correct/len(glob.glob('mask_data/test/1/*')))\n",
    "print(probs)\n",
    "print(classes)\n",
    "print(f\"Prediction: {M_i[classes[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the testing accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `flower_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image along with the top 5 classes\n",
    "\n",
    "# Plot flower input image\n",
    "plt.figure(figsize = (6,10))\n",
    "plot_1 = plt.subplot(2,1,1)\n",
    "\n",
    "#image = process_image('flowers/test/1/image_06743.jpg')\n",
    "image = process_image('flowers/test/15/image_06369.jpg')\n",
    "\n",
    "flower_title = flower_to_name['15']\n",
    "\n",
    "imshow(image, plot_1, title=flower_title);\n",
    "\n",
    "# Convert from the class integer encoding to actual flower names\n",
    "flower_names = [flower_to_name[i] for i in classes]\n",
    "\n",
    "# Plot the probabilities for the top 5 classes as a bar graph\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "sb.barplot(x=probs, y=flower_names, color=sb.color_palette()[0]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
