{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import random as rn\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from PIL import Image\n",
    "import gc\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import glob \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'mask_data'\n",
    "all_data = 'all_data'\n",
    "\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor): \n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the training, validation, and testing sets\n",
    "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                          transforms.Resize(256),#transforms.RandomResizedCrop(224),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225]),\n",
    "                                          AddGaussianNoise(0.1,0.08)])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                              [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "\n",
    "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
    "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
    "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model\n",
    "\n",
    "Load in the pretrained VGG19 model. Freeze the feature and average pool weights and construct the classification component.\n",
    "\n",
    "<img src=\"sketch2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg19(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 10, bias= True)),\n",
    "                                        ('tanh1', nn.Tanh()),\n",
    "                                        ('dropout', nn.Dropout(p=0.25)),\n",
    "                                        ('fc2',nn.Linear(10,2,bias=True)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validateloader, criterion):\n",
    "    \n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for images, labels in iter(validateloader):\n",
    "\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        output = model.forward(images)\n",
    "        val_loss += criterion(output, labels).item()\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        \n",
    "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "Epoch: 1/6..  Training Loss: 0.000..  Validation Loss: 0.703..  Validation Accuracy: 0.473\n",
      "Finished epoch 1 on overall step 1.\n",
      "Finished epoch 1 on overall step 2.\n",
      "Finished epoch 1 on overall step 3.\n",
      "Finished epoch 1 on overall step 4.\n",
      "Finished epoch 1 on overall step 5.\n",
      "Finished epoch 1 on overall step 6.\n",
      "Finished epoch 1 on overall step 7.\n",
      "Finished epoch 1 on overall step 8.\n",
      "Finished epoch 1 on overall step 9.\n",
      "Finished epoch 1 on overall step 10.\n",
      "Finished epoch 1 on overall step 11.\n",
      "Finished epoch 1 on overall step 12.\n",
      "Finished epoch 1 on overall step 13.\n",
      "Finished epoch 1 on overall step 14.\n",
      "Finished epoch 1 on overall step 15.\n",
      "Finished epoch 1 on overall step 16.\n",
      "Finished epoch 1 on overall step 17.\n",
      "Finished epoch 1 on overall step 18.\n",
      "Finished epoch 1 on overall step 19.\n",
      "Finished epoch 1 on overall step 20.\n",
      "Finished epoch 1 on overall step 21.\n",
      "Finished epoch 1 on overall step 22.\n",
      "Finished epoch 1 on overall step 23.\n",
      "Finished epoch 1 on overall step 24.\n",
      "Finished epoch 1 on overall step 25.\n",
      "Finished epoch 1 on overall step 26.\n",
      "Finished epoch 1 on overall step 27.\n",
      "Finished epoch 1 on overall step 28.\n",
      "Finished epoch 1 on overall step 29.\n",
      "Finished epoch 1 on overall step 30.\n",
      "Finished epoch 1 on overall step 31.\n",
      "Finished epoch 1 on overall step 32.\n",
      "Finished epoch 1 on overall step 33.\n",
      "Finished epoch 1 on overall step 34.\n",
      "Finished epoch 1 on overall step 35.\n",
      "Finished epoch 1 on overall step 36.\n",
      "Finished epoch 1 on overall step 37.\n",
      "Finished epoch 1 on overall step 38.\n",
      "Finished epoch 1 on overall step 39.\n",
      "Finished epoch 1 on overall step 40.\n",
      "Finished epoch 1 on overall step 41.\n",
      "Finished epoch 1 on overall step 42.\n",
      "Finished epoch 1 on overall step 43.\n",
      "Finished epoch 1 on overall step 44.\n",
      "Finished epoch 1 on overall step 45.\n",
      "Finished epoch 1 on overall step 46.\n",
      "Finished epoch 1 on overall step 47.\n",
      "Finished epoch 1 on overall step 48.\n",
      "Finished epoch 1 on overall step 49.\n",
      "Finished epoch 1 on overall step 50.\n",
      "Finished epoch 1 on overall step 51.\n",
      "Finished epoch 1 on overall step 52.\n",
      "Finished epoch 1 on overall step 53.\n",
      "Finished epoch 1 on overall step 54.\n",
      "Finished epoch 1 on overall step 55.\n",
      "Finished epoch 1 on overall step 56.\n",
      "Finished epoch 1 on overall step 57.\n",
      "Finished epoch 1 on overall step 58.\n",
      "Finished epoch 1 on overall step 59.\n",
      "Finished epoch 1 on overall step 60.\n",
      "Finished epoch 1 on overall step 61.\n",
      "Finished epoch 1 on overall step 62.\n",
      "Finished epoch 1 on overall step 63.\n",
      "Finished epoch 1 on overall step 64.\n",
      "Finished epoch 1 on overall step 65.\n",
      "Finished epoch 1 on overall step 66.\n",
      "Finished epoch 1 on overall step 67.\n",
      "Finished epoch 1 on overall step 68.\n",
      "Finished epoch 1 on overall step 69.\n",
      "Finished epoch 1 on overall step 70.\n",
      "Finished epoch 1 on overall step 71.\n",
      "Finished epoch 1 on overall step 72.\n",
      "Finished epoch 1 on overall step 73.\n",
      "Finished epoch 1 on overall step 74.\n",
      "Finished epoch 1 on overall step 75.\n",
      "Finished epoch 1 on overall step 76.\n",
      "Finished epoch 1 on overall step 77.\n",
      "Finished epoch 1 on overall step 78.\n",
      "Finished epoch 1 on overall step 79.\n",
      "Finished epoch 1 on overall step 80.\n",
      "Finished epoch 1 on overall step 81.\n",
      "Finished epoch 1 on overall step 82.\n",
      "Finished epoch 1 on overall step 83.\n",
      "Finished epoch 1 on overall step 84.\n",
      "Finished epoch 1 on overall step 85.\n",
      "Finished epoch 1 on overall step 86.\n",
      "Finished epoch 1 on overall step 87.\n",
      "Finished epoch 1 on overall step 88.\n",
      "Finished epoch 1 on overall step 89.\n",
      "Finished epoch 1 on overall step 90.\n",
      "Finished epoch 1 on overall step 91.\n",
      "Finished epoch 1 on overall step 92.\n",
      "Finished epoch 1 on overall step 93.\n",
      "Finished epoch 1 on overall step 94.\n",
      "Finished epoch 1 on overall step 95.\n",
      "Finished epoch 1 on overall step 96.\n",
      "Finished epoch 1 on overall step 97.\n",
      "Finished epoch 1 on overall step 98.\n",
      "Finished epoch 1 on overall step 99.\n",
      "Finished epoch 1 on overall step 100.\n",
      "Epoch: 1/6..  Training Loss: 0.267..  Validation Loss: 0.224..  Validation Accuracy: 0.909\n",
      "Finished epoch 1 on overall step 101.\n",
      "Finished epoch 1 on overall step 102.\n",
      "Finished epoch 1 on overall step 103.\n",
      "Finished epoch 1 on overall step 104.\n",
      "Finished epoch 1 on overall step 105.\n",
      "Finished epoch 1 on overall step 106.\n",
      "Finished epoch 1 on overall step 107.\n",
      "Finished epoch 1 on overall step 108.\n",
      "Finished epoch 1 on overall step 109.\n",
      "Finished epoch 1 on overall step 110.\n",
      "Finished epoch 1 on overall step 111.\n",
      "Finished epoch 1 on overall step 112.\n",
      "Finished epoch 1 on overall step 113.\n",
      "Finished epoch 1 on overall step 114.\n",
      "Finished epoch 1 on overall step 115.\n",
      "Finished epoch 1 on overall step 116.\n",
      "Finished epoch 1 on overall step 117.\n",
      "Finished epoch 1 on overall step 118.\n",
      "Finished epoch 1 on overall step 119.\n",
      "Finished epoch 1 on overall step 120.\n",
      "Finished epoch 1 on overall step 121.\n",
      "Finished epoch 1 on overall step 122.\n",
      "Finished epoch 1 on overall step 123.\n",
      "Finished epoch 1 on overall step 124.\n",
      "Finished epoch 1 on overall step 125.\n",
      "Finished epoch 1 on overall step 126.\n",
      "Finished epoch 1 on overall step 127.\n",
      "Finished epoch 1 on overall step 128.\n",
      "Finished epoch 1 on overall step 129.\n",
      "Finished epoch 1 on overall step 130.\n",
      "Finished epoch 1 on overall step 131.\n",
      "Finished epoch 1 on overall step 132.\n",
      "Finished epoch 1 on overall step 133.\n",
      "Finished epoch 1 on overall step 134.\n",
      "Finished epoch 1 on overall step 135.\n",
      "Finished epoch 1 on overall step 136.\n",
      "Finished epoch 1 on overall step 137.\n",
      "Finished epoch 1 on overall step 138.\n",
      "Finished epoch 1 on overall step 139.\n",
      "Finished epoch 1 on overall step 140.\n",
      "Finished epoch 1 on overall step 141.\n",
      "Finished epoch 1 on overall step 142.\n",
      "Finished epoch 1 on overall step 143.\n",
      "Finished epoch 1 on overall step 144.\n",
      "Finished epoch 1 on overall step 145.\n",
      "Finished epoch 1 on overall step 146.\n",
      "Finished epoch 1 on overall step 147.\n",
      "Finished epoch 1 on overall step 148.\n",
      "Finished epoch 1 on overall step 149.\n",
      "Finished epoch 1 on overall step 150.\n",
      "Finished epoch 1 on overall step 151.\n",
      "Finished epoch 1 on overall step 152.\n",
      "Finished epoch 1 on overall step 153.\n",
      "Finished epoch 1 on overall step 154.\n",
      "Finished epoch 1 on overall step 155.\n",
      "Finished epoch 1 on overall step 156.\n",
      "Finished epoch 1 on overall step 157.\n",
      "Finished epoch 1 on overall step 158.\n",
      "Finished epoch 1 on overall step 159.\n",
      "Finished epoch 1 on overall step 160.\n",
      "Finished epoch 1 on overall step 161.\n",
      "Finished epoch 1 on overall step 162.\n",
      "Finished epoch 1 on overall step 163.\n",
      "Finished epoch 1 on overall step 164.\n",
      "Finished epoch 1 on overall step 165.\n",
      "Finished epoch 1 on overall step 166.\n",
      "Finished epoch 1 on overall step 167.\n",
      "Finished epoch 1 on overall step 168.\n",
      "Finished epoch 1 on overall step 169.\n",
      "Finished epoch 1 on overall step 170.\n",
      "Finished epoch 1 on overall step 171.\n",
      "Finished epoch 1 on overall step 172.\n",
      "Finished epoch 1 on overall step 173.\n",
      "Finished epoch 1 on overall step 174.\n",
      "Finished epoch 1 on overall step 175.\n",
      "Finished epoch 1 on overall step 176.\n",
      "Finished epoch 1 on overall step 177.\n",
      "Finished epoch 1 on overall step 178.\n",
      "Finished epoch 1 on overall step 179.\n",
      "Finished epoch 1 on overall step 180.\n",
      "Finished epoch 1 on overall step 181.\n",
      "Finished epoch 1 on overall step 182.\n",
      "Finished epoch 2 on overall step 183.\n",
      "Finished epoch 2 on overall step 184.\n",
      "Finished epoch 2 on overall step 185.\n",
      "Finished epoch 2 on overall step 186.\n",
      "Finished epoch 2 on overall step 187.\n",
      "Finished epoch 2 on overall step 188.\n",
      "Finished epoch 2 on overall step 189.\n",
      "Finished epoch 2 on overall step 190.\n",
      "Finished epoch 2 on overall step 191.\n",
      "Finished epoch 2 on overall step 192.\n",
      "Finished epoch 2 on overall step 193.\n",
      "Finished epoch 2 on overall step 194.\n",
      "Finished epoch 2 on overall step 195.\n",
      "Finished epoch 2 on overall step 196.\n",
      "Finished epoch 2 on overall step 197.\n",
      "Finished epoch 2 on overall step 198.\n",
      "Finished epoch 2 on overall step 199.\n",
      "Finished epoch 2 on overall step 200.\n",
      "Epoch: 2/6..  Training Loss: 0.024..  Validation Loss: 0.179..  Validation Accuracy: 0.934\n",
      "Finished epoch 2 on overall step 201.\n",
      "Finished epoch 2 on overall step 202.\n",
      "Finished epoch 2 on overall step 203.\n",
      "Finished epoch 2 on overall step 204.\n",
      "Finished epoch 2 on overall step 205.\n",
      "Finished epoch 2 on overall step 206.\n",
      "Finished epoch 2 on overall step 207.\n",
      "Finished epoch 2 on overall step 208.\n",
      "Finished epoch 2 on overall step 209.\n",
      "Finished epoch 2 on overall step 210.\n",
      "Finished epoch 2 on overall step 211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 2 on overall step 212.\n",
      "Finished epoch 2 on overall step 213.\n",
      "Finished epoch 2 on overall step 214.\n",
      "Finished epoch 2 on overall step 215.\n",
      "Finished epoch 2 on overall step 216.\n",
      "Finished epoch 2 on overall step 217.\n",
      "Finished epoch 2 on overall step 218.\n",
      "Finished epoch 2 on overall step 219.\n",
      "Finished epoch 2 on overall step 220.\n",
      "Finished epoch 2 on overall step 221.\n",
      "Finished epoch 2 on overall step 222.\n",
      "Finished epoch 2 on overall step 223.\n",
      "Finished epoch 2 on overall step 224.\n",
      "Finished epoch 2 on overall step 225.\n",
      "Finished epoch 2 on overall step 226.\n",
      "Finished epoch 2 on overall step 227.\n",
      "Finished epoch 2 on overall step 228.\n",
      "Finished epoch 2 on overall step 229.\n",
      "Finished epoch 2 on overall step 230.\n",
      "Finished epoch 2 on overall step 231.\n",
      "Finished epoch 2 on overall step 232.\n",
      "Finished epoch 2 on overall step 233.\n",
      "Finished epoch 2 on overall step 234.\n",
      "Finished epoch 2 on overall step 235.\n",
      "Finished epoch 2 on overall step 236.\n",
      "Finished epoch 2 on overall step 237.\n",
      "Finished epoch 2 on overall step 238.\n",
      "Finished epoch 2 on overall step 239.\n",
      "Finished epoch 2 on overall step 240.\n",
      "Finished epoch 2 on overall step 241.\n",
      "Finished epoch 2 on overall step 242.\n",
      "Finished epoch 2 on overall step 243.\n",
      "Finished epoch 2 on overall step 244.\n",
      "Finished epoch 2 on overall step 245.\n",
      "Finished epoch 2 on overall step 246.\n",
      "Finished epoch 2 on overall step 247.\n",
      "Finished epoch 2 on overall step 248.\n",
      "Finished epoch 2 on overall step 249.\n",
      "Finished epoch 2 on overall step 250.\n",
      "Finished epoch 2 on overall step 251.\n",
      "Finished epoch 2 on overall step 252.\n",
      "Finished epoch 2 on overall step 253.\n",
      "Finished epoch 2 on overall step 254.\n",
      "Finished epoch 2 on overall step 255.\n",
      "Finished epoch 2 on overall step 256.\n",
      "Finished epoch 2 on overall step 257.\n",
      "Finished epoch 2 on overall step 258.\n",
      "Finished epoch 2 on overall step 259.\n",
      "Finished epoch 2 on overall step 260.\n",
      "Finished epoch 2 on overall step 261.\n",
      "Finished epoch 2 on overall step 262.\n",
      "Finished epoch 2 on overall step 263.\n",
      "Finished epoch 2 on overall step 264.\n",
      "Finished epoch 2 on overall step 265.\n",
      "Finished epoch 2 on overall step 266.\n",
      "Finished epoch 2 on overall step 267.\n",
      "Finished epoch 2 on overall step 268.\n",
      "Finished epoch 2 on overall step 269.\n",
      "Finished epoch 2 on overall step 270.\n",
      "Finished epoch 2 on overall step 271.\n",
      "Finished epoch 2 on overall step 272.\n",
      "Finished epoch 2 on overall step 273.\n",
      "Finished epoch 2 on overall step 274.\n",
      "Finished epoch 2 on overall step 275.\n",
      "Finished epoch 2 on overall step 276.\n",
      "Finished epoch 2 on overall step 277.\n",
      "Finished epoch 2 on overall step 278.\n",
      "Finished epoch 2 on overall step 279.\n",
      "Finished epoch 2 on overall step 280.\n",
      "Finished epoch 2 on overall step 281.\n",
      "Finished epoch 2 on overall step 282.\n",
      "Finished epoch 2 on overall step 283.\n",
      "Finished epoch 2 on overall step 284.\n",
      "Finished epoch 2 on overall step 285.\n",
      "Finished epoch 2 on overall step 286.\n",
      "Finished epoch 2 on overall step 287.\n",
      "Finished epoch 2 on overall step 288.\n",
      "Finished epoch 2 on overall step 289.\n",
      "Finished epoch 2 on overall step 290.\n",
      "Finished epoch 2 on overall step 291.\n",
      "Finished epoch 2 on overall step 292.\n",
      "Finished epoch 2 on overall step 293.\n",
      "Finished epoch 2 on overall step 294.\n",
      "Finished epoch 2 on overall step 295.\n",
      "Finished epoch 2 on overall step 296.\n",
      "Finished epoch 2 on overall step 297.\n",
      "Finished epoch 2 on overall step 298.\n",
      "Finished epoch 2 on overall step 299.\n",
      "Finished epoch 2 on overall step 300.\n",
      "Epoch: 2/6..  Training Loss: 0.146..  Validation Loss: 0.142..  Validation Accuracy: 0.949\n",
      "Finished epoch 2 on overall step 301.\n",
      "Finished epoch 2 on overall step 302.\n",
      "Finished epoch 2 on overall step 303.\n",
      "Finished epoch 2 on overall step 304.\n",
      "Finished epoch 2 on overall step 305.\n",
      "Finished epoch 2 on overall step 306.\n",
      "Finished epoch 2 on overall step 307.\n",
      "Finished epoch 2 on overall step 308.\n",
      "Finished epoch 2 on overall step 309.\n",
      "Finished epoch 2 on overall step 310.\n",
      "Finished epoch 2 on overall step 311.\n",
      "Finished epoch 2 on overall step 312.\n",
      "Finished epoch 2 on overall step 313.\n",
      "Finished epoch 2 on overall step 314.\n",
      "Finished epoch 2 on overall step 315.\n",
      "Finished epoch 2 on overall step 316.\n",
      "Finished epoch 2 on overall step 317.\n",
      "Finished epoch 2 on overall step 318.\n",
      "Finished epoch 2 on overall step 319.\n",
      "Finished epoch 2 on overall step 320.\n",
      "Finished epoch 2 on overall step 321.\n",
      "Finished epoch 2 on overall step 322.\n",
      "Finished epoch 2 on overall step 323.\n",
      "Finished epoch 2 on overall step 324.\n",
      "Finished epoch 2 on overall step 325.\n",
      "Finished epoch 2 on overall step 326.\n",
      "Finished epoch 2 on overall step 327.\n",
      "Finished epoch 2 on overall step 328.\n",
      "Finished epoch 2 on overall step 329.\n",
      "Finished epoch 2 on overall step 330.\n",
      "Finished epoch 2 on overall step 331.\n",
      "Finished epoch 2 on overall step 332.\n",
      "Finished epoch 2 on overall step 333.\n",
      "Finished epoch 2 on overall step 334.\n",
      "Finished epoch 2 on overall step 335.\n",
      "Finished epoch 2 on overall step 336.\n",
      "Finished epoch 2 on overall step 337.\n",
      "Finished epoch 2 on overall step 338.\n",
      "Finished epoch 2 on overall step 339.\n",
      "Finished epoch 2 on overall step 340.\n",
      "Finished epoch 2 on overall step 341.\n",
      "Finished epoch 2 on overall step 342.\n",
      "Finished epoch 2 on overall step 343.\n",
      "Finished epoch 2 on overall step 344.\n",
      "Finished epoch 2 on overall step 345.\n",
      "Finished epoch 2 on overall step 346.\n",
      "Finished epoch 2 on overall step 347.\n",
      "Finished epoch 2 on overall step 348.\n",
      "Finished epoch 2 on overall step 349.\n",
      "Finished epoch 2 on overall step 350.\n",
      "Finished epoch 2 on overall step 351.\n",
      "Finished epoch 2 on overall step 352.\n",
      "Finished epoch 2 on overall step 353.\n",
      "Finished epoch 2 on overall step 354.\n",
      "Finished epoch 2 on overall step 355.\n",
      "Finished epoch 2 on overall step 356.\n",
      "Finished epoch 2 on overall step 357.\n",
      "Finished epoch 2 on overall step 358.\n",
      "Finished epoch 2 on overall step 359.\n",
      "Finished epoch 2 on overall step 360.\n",
      "Finished epoch 2 on overall step 361.\n",
      "Finished epoch 2 on overall step 362.\n",
      "Finished epoch 2 on overall step 363.\n",
      "Finished epoch 2 on overall step 364.\n",
      "Finished epoch 3 on overall step 365.\n",
      "Finished epoch 3 on overall step 366.\n",
      "Finished epoch 3 on overall step 367.\n",
      "Finished epoch 3 on overall step 368.\n",
      "Finished epoch 3 on overall step 369.\n",
      "Finished epoch 3 on overall step 370.\n",
      "Finished epoch 3 on overall step 371.\n",
      "Finished epoch 3 on overall step 372.\n",
      "Finished epoch 3 on overall step 373.\n",
      "Finished epoch 3 on overall step 374.\n",
      "Finished epoch 3 on overall step 375.\n",
      "Finished epoch 3 on overall step 376.\n",
      "Finished epoch 3 on overall step 377.\n",
      "Finished epoch 3 on overall step 378.\n",
      "Finished epoch 3 on overall step 379.\n",
      "Finished epoch 3 on overall step 380.\n",
      "Finished epoch 3 on overall step 381.\n",
      "Finished epoch 3 on overall step 382.\n",
      "Finished epoch 3 on overall step 383.\n",
      "Finished epoch 3 on overall step 384.\n",
      "Finished epoch 3 on overall step 385.\n",
      "Finished epoch 3 on overall step 386.\n",
      "Finished epoch 3 on overall step 387.\n",
      "Finished epoch 3 on overall step 388.\n",
      "Finished epoch 3 on overall step 389.\n",
      "Finished epoch 3 on overall step 390.\n",
      "Finished epoch 3 on overall step 391.\n",
      "Finished epoch 3 on overall step 392.\n",
      "Finished epoch 3 on overall step 393.\n",
      "Finished epoch 3 on overall step 394.\n",
      "Finished epoch 3 on overall step 395.\n",
      "Finished epoch 3 on overall step 396.\n",
      "Finished epoch 3 on overall step 397.\n",
      "Finished epoch 3 on overall step 398.\n",
      "Finished epoch 3 on overall step 399.\n",
      "Finished epoch 3 on overall step 400.\n",
      "Epoch: 3/6..  Training Loss: 0.053..  Validation Loss: 0.141..  Validation Accuracy: 0.945\n",
      "Finished epoch 3 on overall step 401.\n",
      "Finished epoch 3 on overall step 402.\n",
      "Finished epoch 3 on overall step 403.\n",
      "Finished epoch 3 on overall step 404.\n",
      "Finished epoch 3 on overall step 405.\n",
      "Finished epoch 3 on overall step 406.\n",
      "Finished epoch 3 on overall step 407.\n",
      "Finished epoch 3 on overall step 408.\n",
      "Finished epoch 3 on overall step 409.\n",
      "Finished epoch 3 on overall step 410.\n",
      "Finished epoch 3 on overall step 411.\n",
      "Finished epoch 3 on overall step 412.\n",
      "Finished epoch 3 on overall step 413.\n",
      "Finished epoch 3 on overall step 414.\n",
      "Finished epoch 3 on overall step 415.\n",
      "Finished epoch 3 on overall step 416.\n",
      "Finished epoch 3 on overall step 417.\n",
      "Finished epoch 3 on overall step 418.\n",
      "Finished epoch 3 on overall step 419.\n",
      "Finished epoch 3 on overall step 420.\n",
      "Finished epoch 3 on overall step 421.\n",
      "Finished epoch 3 on overall step 422.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 3 on overall step 423.\n",
      "Finished epoch 3 on overall step 424.\n",
      "Finished epoch 3 on overall step 425.\n",
      "Finished epoch 3 on overall step 426.\n",
      "Finished epoch 3 on overall step 427.\n",
      "Finished epoch 3 on overall step 428.\n",
      "Finished epoch 3 on overall step 429.\n",
      "Finished epoch 3 on overall step 430.\n",
      "Finished epoch 3 on overall step 431.\n",
      "Finished epoch 3 on overall step 432.\n",
      "Finished epoch 3 on overall step 433.\n",
      "Finished epoch 3 on overall step 434.\n",
      "Finished epoch 3 on overall step 435.\n",
      "Finished epoch 3 on overall step 436.\n",
      "Finished epoch 3 on overall step 437.\n",
      "Finished epoch 3 on overall step 438.\n",
      "Finished epoch 3 on overall step 439.\n",
      "Finished epoch 3 on overall step 440.\n",
      "Finished epoch 3 on overall step 441.\n",
      "Finished epoch 3 on overall step 442.\n",
      "Finished epoch 3 on overall step 443.\n",
      "Finished epoch 3 on overall step 444.\n",
      "Finished epoch 3 on overall step 445.\n",
      "Finished epoch 3 on overall step 446.\n",
      "Finished epoch 3 on overall step 447.\n",
      "Finished epoch 3 on overall step 448.\n",
      "Finished epoch 3 on overall step 449.\n",
      "Finished epoch 3 on overall step 450.\n",
      "Finished epoch 3 on overall step 451.\n",
      "Finished epoch 3 on overall step 452.\n",
      "Finished epoch 3 on overall step 453.\n",
      "Finished epoch 3 on overall step 454.\n",
      "Finished epoch 3 on overall step 455.\n",
      "Finished epoch 3 on overall step 456.\n",
      "Finished epoch 3 on overall step 457.\n",
      "Finished epoch 3 on overall step 458.\n",
      "Finished epoch 3 on overall step 459.\n",
      "Finished epoch 3 on overall step 460.\n",
      "Finished epoch 3 on overall step 461.\n",
      "Finished epoch 3 on overall step 462.\n",
      "Finished epoch 3 on overall step 463.\n",
      "Finished epoch 3 on overall step 464.\n",
      "Finished epoch 3 on overall step 465.\n",
      "Finished epoch 3 on overall step 466.\n",
      "Finished epoch 3 on overall step 467.\n",
      "Finished epoch 3 on overall step 468.\n",
      "Finished epoch 3 on overall step 469.\n",
      "Finished epoch 3 on overall step 470.\n",
      "Finished epoch 3 on overall step 471.\n",
      "Finished epoch 3 on overall step 472.\n",
      "Finished epoch 3 on overall step 473.\n",
      "Finished epoch 3 on overall step 474.\n",
      "Finished epoch 3 on overall step 475.\n",
      "Finished epoch 3 on overall step 476.\n",
      "Finished epoch 3 on overall step 477.\n",
      "Finished epoch 3 on overall step 478.\n",
      "Finished epoch 3 on overall step 479.\n",
      "Finished epoch 3 on overall step 480.\n",
      "Finished epoch 3 on overall step 481.\n",
      "Finished epoch 3 on overall step 482.\n",
      "Finished epoch 3 on overall step 483.\n",
      "Finished epoch 3 on overall step 484.\n",
      "Finished epoch 3 on overall step 485.\n",
      "Finished epoch 3 on overall step 486.\n",
      "Finished epoch 3 on overall step 487.\n",
      "Finished epoch 3 on overall step 488.\n",
      "Finished epoch 3 on overall step 489.\n",
      "Finished epoch 3 on overall step 490.\n",
      "Finished epoch 3 on overall step 491.\n",
      "Finished epoch 3 on overall step 492.\n",
      "Finished epoch 3 on overall step 493.\n",
      "Finished epoch 3 on overall step 494.\n",
      "Finished epoch 3 on overall step 495.\n",
      "Finished epoch 3 on overall step 496.\n",
      "Finished epoch 3 on overall step 497.\n",
      "Finished epoch 3 on overall step 498.\n",
      "Finished epoch 3 on overall step 499.\n",
      "Finished epoch 3 on overall step 500.\n",
      "Epoch: 3/6..  Training Loss: 0.133..  Validation Loss: 0.188..  Validation Accuracy: 0.924\n",
      "Finished epoch 3 on overall step 501.\n",
      "Finished epoch 3 on overall step 502.\n",
      "Finished epoch 3 on overall step 503.\n",
      "Finished epoch 3 on overall step 504.\n",
      "Finished epoch 3 on overall step 505.\n",
      "Finished epoch 3 on overall step 506.\n",
      "Finished epoch 3 on overall step 507.\n",
      "Finished epoch 3 on overall step 508.\n",
      "Finished epoch 3 on overall step 509.\n",
      "Finished epoch 3 on overall step 510.\n",
      "Finished epoch 3 on overall step 511.\n",
      "Finished epoch 3 on overall step 512.\n",
      "Finished epoch 3 on overall step 513.\n",
      "Finished epoch 3 on overall step 514.\n",
      "Finished epoch 3 on overall step 515.\n",
      "Finished epoch 3 on overall step 516.\n",
      "Finished epoch 3 on overall step 517.\n",
      "Finished epoch 3 on overall step 518.\n",
      "Finished epoch 3 on overall step 519.\n",
      "Finished epoch 3 on overall step 520.\n",
      "Finished epoch 3 on overall step 521.\n",
      "Finished epoch 3 on overall step 522.\n",
      "Finished epoch 3 on overall step 523.\n",
      "Finished epoch 3 on overall step 524.\n",
      "Finished epoch 3 on overall step 525.\n",
      "Finished epoch 3 on overall step 526.\n",
      "Finished epoch 3 on overall step 527.\n",
      "Finished epoch 3 on overall step 528.\n",
      "Finished epoch 3 on overall step 529.\n",
      "Finished epoch 3 on overall step 530.\n",
      "Finished epoch 3 on overall step 531.\n",
      "Finished epoch 3 on overall step 532.\n",
      "Finished epoch 3 on overall step 533.\n",
      "Finished epoch 3 on overall step 534.\n",
      "Finished epoch 3 on overall step 535.\n",
      "Finished epoch 3 on overall step 536.\n",
      "Finished epoch 3 on overall step 537.\n",
      "Finished epoch 3 on overall step 538.\n",
      "Finished epoch 3 on overall step 539.\n",
      "Finished epoch 3 on overall step 540.\n",
      "Finished epoch 3 on overall step 541.\n",
      "Finished epoch 3 on overall step 542.\n",
      "Finished epoch 3 on overall step 543.\n",
      "Finished epoch 3 on overall step 544.\n",
      "Finished epoch 3 on overall step 545.\n",
      "Finished epoch 3 on overall step 546.\n",
      "Finished epoch 4 on overall step 547.\n",
      "Finished epoch 4 on overall step 548.\n",
      "Finished epoch 4 on overall step 549.\n",
      "Finished epoch 4 on overall step 550.\n",
      "Finished epoch 4 on overall step 551.\n",
      "Finished epoch 4 on overall step 552.\n",
      "Finished epoch 4 on overall step 553.\n",
      "Finished epoch 4 on overall step 554.\n",
      "Finished epoch 4 on overall step 555.\n",
      "Finished epoch 4 on overall step 556.\n",
      "Finished epoch 4 on overall step 557.\n",
      "Finished epoch 4 on overall step 558.\n",
      "Finished epoch 4 on overall step 559.\n",
      "Finished epoch 4 on overall step 560.\n",
      "Finished epoch 4 on overall step 561.\n",
      "Finished epoch 4 on overall step 562.\n",
      "Finished epoch 4 on overall step 563.\n",
      "Finished epoch 4 on overall step 564.\n",
      "Finished epoch 4 on overall step 565.\n",
      "Finished epoch 4 on overall step 566.\n",
      "Finished epoch 4 on overall step 567.\n",
      "Finished epoch 4 on overall step 568.\n",
      "Finished epoch 4 on overall step 569.\n",
      "Finished epoch 4 on overall step 570.\n",
      "Finished epoch 4 on overall step 571.\n",
      "Finished epoch 4 on overall step 572.\n",
      "Finished epoch 4 on overall step 573.\n",
      "Finished epoch 4 on overall step 574.\n",
      "Finished epoch 4 on overall step 575.\n",
      "Finished epoch 4 on overall step 576.\n",
      "Finished epoch 4 on overall step 577.\n",
      "Finished epoch 4 on overall step 578.\n",
      "Finished epoch 4 on overall step 579.\n",
      "Finished epoch 4 on overall step 580.\n",
      "Finished epoch 4 on overall step 581.\n",
      "Finished epoch 4 on overall step 582.\n",
      "Finished epoch 4 on overall step 583.\n",
      "Finished epoch 4 on overall step 584.\n",
      "Finished epoch 4 on overall step 585.\n",
      "Finished epoch 4 on overall step 586.\n",
      "Finished epoch 4 on overall step 587.\n",
      "Finished epoch 4 on overall step 588.\n",
      "Finished epoch 4 on overall step 589.\n",
      "Finished epoch 4 on overall step 590.\n",
      "Finished epoch 4 on overall step 591.\n",
      "Finished epoch 4 on overall step 592.\n",
      "Finished epoch 4 on overall step 593.\n",
      "Finished epoch 4 on overall step 594.\n",
      "Finished epoch 4 on overall step 595.\n",
      "Finished epoch 4 on overall step 596.\n",
      "Finished epoch 4 on overall step 597.\n",
      "Finished epoch 4 on overall step 598.\n",
      "Finished epoch 4 on overall step 599.\n",
      "Finished epoch 4 on overall step 600.\n",
      "Epoch: 4/6..  Training Loss: 0.063..  Validation Loss: 0.147..  Validation Accuracy: 0.943\n",
      "Finished epoch 4 on overall step 601.\n",
      "Finished epoch 4 on overall step 602.\n",
      "Finished epoch 4 on overall step 603.\n",
      "Finished epoch 4 on overall step 604.\n",
      "Finished epoch 4 on overall step 605.\n",
      "Finished epoch 4 on overall step 606.\n",
      "Finished epoch 4 on overall step 607.\n",
      "Finished epoch 4 on overall step 608.\n",
      "Finished epoch 4 on overall step 609.\n",
      "Finished epoch 4 on overall step 610.\n",
      "Finished epoch 4 on overall step 611.\n",
      "Finished epoch 4 on overall step 612.\n",
      "Finished epoch 4 on overall step 613.\n",
      "Finished epoch 4 on overall step 614.\n",
      "Finished epoch 4 on overall step 615.\n",
      "Finished epoch 4 on overall step 616.\n",
      "Finished epoch 4 on overall step 617.\n",
      "Finished epoch 4 on overall step 618.\n",
      "Finished epoch 4 on overall step 619.\n",
      "Finished epoch 4 on overall step 620.\n",
      "Finished epoch 4 on overall step 621.\n",
      "Finished epoch 4 on overall step 622.\n",
      "Finished epoch 4 on overall step 623.\n",
      "Finished epoch 4 on overall step 624.\n",
      "Finished epoch 4 on overall step 625.\n",
      "Finished epoch 4 on overall step 626.\n",
      "Finished epoch 4 on overall step 627.\n",
      "Finished epoch 4 on overall step 628.\n",
      "Finished epoch 4 on overall step 629.\n",
      "Finished epoch 4 on overall step 630.\n",
      "Finished epoch 4 on overall step 631.\n",
      "Finished epoch 4 on overall step 632.\n",
      "Finished epoch 4 on overall step 633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 4 on overall step 634.\n",
      "Finished epoch 4 on overall step 635.\n",
      "Finished epoch 4 on overall step 636.\n",
      "Finished epoch 4 on overall step 637.\n",
      "Finished epoch 4 on overall step 638.\n",
      "Finished epoch 4 on overall step 639.\n",
      "Finished epoch 4 on overall step 640.\n",
      "Finished epoch 4 on overall step 641.\n",
      "Finished epoch 4 on overall step 642.\n",
      "Finished epoch 4 on overall step 643.\n",
      "Finished epoch 4 on overall step 644.\n",
      "Finished epoch 4 on overall step 645.\n",
      "Finished epoch 4 on overall step 646.\n",
      "Finished epoch 4 on overall step 647.\n",
      "Finished epoch 4 on overall step 648.\n",
      "Finished epoch 4 on overall step 649.\n",
      "Finished epoch 4 on overall step 650.\n",
      "Finished epoch 4 on overall step 651.\n",
      "Finished epoch 4 on overall step 652.\n",
      "Finished epoch 4 on overall step 653.\n",
      "Finished epoch 4 on overall step 654.\n",
      "Finished epoch 4 on overall step 655.\n",
      "Finished epoch 4 on overall step 656.\n",
      "Finished epoch 4 on overall step 657.\n",
      "Finished epoch 4 on overall step 658.\n",
      "Finished epoch 4 on overall step 659.\n",
      "Finished epoch 4 on overall step 660.\n",
      "Finished epoch 4 on overall step 661.\n",
      "Finished epoch 4 on overall step 662.\n",
      "Finished epoch 4 on overall step 663.\n",
      "Finished epoch 4 on overall step 664.\n",
      "Finished epoch 4 on overall step 665.\n",
      "Finished epoch 4 on overall step 666.\n",
      "Finished epoch 4 on overall step 667.\n",
      "Finished epoch 4 on overall step 668.\n",
      "Finished epoch 4 on overall step 669.\n",
      "Finished epoch 4 on overall step 670.\n",
      "Finished epoch 4 on overall step 671.\n",
      "Finished epoch 4 on overall step 672.\n",
      "Finished epoch 4 on overall step 673.\n",
      "Finished epoch 4 on overall step 674.\n",
      "Finished epoch 4 on overall step 675.\n",
      "Finished epoch 4 on overall step 676.\n",
      "Finished epoch 4 on overall step 677.\n",
      "Finished epoch 4 on overall step 678.\n",
      "Finished epoch 4 on overall step 679.\n",
      "Finished epoch 4 on overall step 680.\n",
      "Finished epoch 4 on overall step 681.\n",
      "Finished epoch 4 on overall step 682.\n",
      "Finished epoch 4 on overall step 683.\n",
      "Finished epoch 4 on overall step 684.\n",
      "Finished epoch 4 on overall step 685.\n",
      "Finished epoch 4 on overall step 686.\n",
      "Finished epoch 4 on overall step 687.\n",
      "Finished epoch 4 on overall step 688.\n",
      "Finished epoch 4 on overall step 689.\n",
      "Finished epoch 4 on overall step 690.\n",
      "Finished epoch 4 on overall step 691.\n",
      "Finished epoch 4 on overall step 692.\n",
      "Finished epoch 4 on overall step 693.\n",
      "Finished epoch 4 on overall step 694.\n",
      "Finished epoch 4 on overall step 695.\n",
      "Finished epoch 4 on overall step 696.\n",
      "Finished epoch 4 on overall step 697.\n",
      "Finished epoch 4 on overall step 698.\n",
      "Finished epoch 4 on overall step 699.\n",
      "Finished epoch 4 on overall step 700.\n",
      "Epoch: 4/6..  Training Loss: 0.126..  Validation Loss: 0.126..  Validation Accuracy: 0.953\n",
      "Finished epoch 4 on overall step 701.\n",
      "Finished epoch 4 on overall step 702.\n",
      "Finished epoch 4 on overall step 703.\n",
      "Finished epoch 4 on overall step 704.\n",
      "Finished epoch 4 on overall step 705.\n",
      "Finished epoch 4 on overall step 706.\n",
      "Finished epoch 4 on overall step 707.\n",
      "Finished epoch 4 on overall step 708.\n",
      "Finished epoch 4 on overall step 709.\n",
      "Finished epoch 4 on overall step 710.\n",
      "Finished epoch 4 on overall step 711.\n",
      "Finished epoch 4 on overall step 712.\n",
      "Finished epoch 4 on overall step 713.\n",
      "Finished epoch 4 on overall step 714.\n",
      "Finished epoch 4 on overall step 715.\n",
      "Finished epoch 4 on overall step 716.\n",
      "Finished epoch 4 on overall step 717.\n",
      "Finished epoch 4 on overall step 718.\n",
      "Finished epoch 4 on overall step 719.\n",
      "Finished epoch 4 on overall step 720.\n",
      "Finished epoch 4 on overall step 721.\n",
      "Finished epoch 4 on overall step 722.\n",
      "Finished epoch 4 on overall step 723.\n",
      "Finished epoch 4 on overall step 724.\n",
      "Finished epoch 4 on overall step 725.\n",
      "Finished epoch 4 on overall step 726.\n",
      "Finished epoch 4 on overall step 727.\n",
      "Finished epoch 4 on overall step 728.\n",
      "Finished epoch 5 on overall step 729.\n",
      "Finished epoch 5 on overall step 730.\n",
      "Finished epoch 5 on overall step 731.\n",
      "Finished epoch 5 on overall step 732.\n",
      "Finished epoch 5 on overall step 733.\n",
      "Finished epoch 5 on overall step 734.\n",
      "Finished epoch 5 on overall step 735.\n",
      "Finished epoch 5 on overall step 736.\n",
      "Finished epoch 5 on overall step 737.\n",
      "Finished epoch 5 on overall step 738.\n",
      "Finished epoch 5 on overall step 739.\n",
      "Finished epoch 5 on overall step 740.\n",
      "Finished epoch 5 on overall step 741.\n",
      "Finished epoch 5 on overall step 742.\n",
      "Finished epoch 5 on overall step 743.\n",
      "Finished epoch 5 on overall step 744.\n",
      "Finished epoch 5 on overall step 745.\n",
      "Finished epoch 5 on overall step 746.\n",
      "Finished epoch 5 on overall step 747.\n",
      "Finished epoch 5 on overall step 748.\n",
      "Finished epoch 5 on overall step 749.\n",
      "Finished epoch 5 on overall step 750.\n",
      "Finished epoch 5 on overall step 751.\n",
      "Finished epoch 5 on overall step 752.\n",
      "Finished epoch 5 on overall step 753.\n",
      "Finished epoch 5 on overall step 754.\n",
      "Finished epoch 5 on overall step 755.\n",
      "Finished epoch 5 on overall step 756.\n",
      "Finished epoch 5 on overall step 757.\n",
      "Finished epoch 5 on overall step 758.\n",
      "Finished epoch 5 on overall step 759.\n",
      "Finished epoch 5 on overall step 760.\n",
      "Finished epoch 5 on overall step 761.\n",
      "Finished epoch 5 on overall step 762.\n",
      "Finished epoch 5 on overall step 763.\n",
      "Finished epoch 5 on overall step 764.\n",
      "Finished epoch 5 on overall step 765.\n",
      "Finished epoch 5 on overall step 766.\n",
      "Finished epoch 5 on overall step 767.\n",
      "Finished epoch 5 on overall step 768.\n",
      "Finished epoch 5 on overall step 769.\n",
      "Finished epoch 5 on overall step 770.\n",
      "Finished epoch 5 on overall step 771.\n",
      "Finished epoch 5 on overall step 772.\n",
      "Finished epoch 5 on overall step 773.\n",
      "Finished epoch 5 on overall step 774.\n",
      "Finished epoch 5 on overall step 775.\n",
      "Finished epoch 5 on overall step 776.\n",
      "Finished epoch 5 on overall step 777.\n",
      "Finished epoch 5 on overall step 778.\n",
      "Finished epoch 5 on overall step 779.\n",
      "Finished epoch 5 on overall step 780.\n",
      "Finished epoch 5 on overall step 781.\n",
      "Finished epoch 5 on overall step 782.\n",
      "Finished epoch 5 on overall step 783.\n",
      "Finished epoch 5 on overall step 784.\n",
      "Finished epoch 5 on overall step 785.\n",
      "Finished epoch 5 on overall step 786.\n",
      "Finished epoch 5 on overall step 787.\n",
      "Finished epoch 5 on overall step 788.\n",
      "Finished epoch 5 on overall step 789.\n",
      "Finished epoch 5 on overall step 790.\n",
      "Finished epoch 5 on overall step 791.\n",
      "Finished epoch 5 on overall step 792.\n",
      "Finished epoch 5 on overall step 793.\n",
      "Finished epoch 5 on overall step 794.\n",
      "Finished epoch 5 on overall step 795.\n",
      "Finished epoch 5 on overall step 796.\n",
      "Finished epoch 5 on overall step 797.\n",
      "Finished epoch 5 on overall step 798.\n",
      "Finished epoch 5 on overall step 799.\n",
      "Finished epoch 5 on overall step 800.\n",
      "Epoch: 5/6..  Training Loss: 0.085..  Validation Loss: 0.144..  Validation Accuracy: 0.946\n",
      "Finished epoch 5 on overall step 801.\n",
      "Finished epoch 5 on overall step 802.\n",
      "Finished epoch 5 on overall step 803.\n",
      "Finished epoch 5 on overall step 804.\n",
      "Finished epoch 5 on overall step 805.\n",
      "Finished epoch 5 on overall step 806.\n",
      "Finished epoch 5 on overall step 807.\n",
      "Finished epoch 5 on overall step 808.\n",
      "Finished epoch 5 on overall step 809.\n",
      "Finished epoch 5 on overall step 810.\n",
      "Finished epoch 5 on overall step 811.\n",
      "Finished epoch 5 on overall step 812.\n",
      "Finished epoch 5 on overall step 813.\n",
      "Finished epoch 5 on overall step 814.\n",
      "Finished epoch 5 on overall step 815.\n",
      "Finished epoch 5 on overall step 816.\n",
      "Finished epoch 5 on overall step 817.\n",
      "Finished epoch 5 on overall step 818.\n",
      "Finished epoch 5 on overall step 819.\n",
      "Finished epoch 5 on overall step 820.\n",
      "Finished epoch 5 on overall step 821.\n",
      "Finished epoch 5 on overall step 822.\n",
      "Finished epoch 5 on overall step 823.\n",
      "Finished epoch 5 on overall step 824.\n",
      "Finished epoch 5 on overall step 825.\n",
      "Finished epoch 5 on overall step 826.\n",
      "Finished epoch 5 on overall step 827.\n",
      "Finished epoch 5 on overall step 828.\n",
      "Finished epoch 5 on overall step 829.\n",
      "Finished epoch 5 on overall step 830.\n",
      "Finished epoch 5 on overall step 831.\n",
      "Finished epoch 5 on overall step 832.\n",
      "Finished epoch 5 on overall step 833.\n",
      "Finished epoch 5 on overall step 834.\n",
      "Finished epoch 5 on overall step 835.\n",
      "Finished epoch 5 on overall step 836.\n",
      "Finished epoch 5 on overall step 837.\n",
      "Finished epoch 5 on overall step 838.\n",
      "Finished epoch 5 on overall step 839.\n",
      "Finished epoch 5 on overall step 840.\n",
      "Finished epoch 5 on overall step 841.\n",
      "Finished epoch 5 on overall step 842.\n",
      "Finished epoch 5 on overall step 843.\n",
      "Finished epoch 5 on overall step 844.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 5 on overall step 845.\n",
      "Finished epoch 5 on overall step 846.\n",
      "Finished epoch 5 on overall step 847.\n",
      "Finished epoch 5 on overall step 848.\n",
      "Finished epoch 5 on overall step 849.\n",
      "Finished epoch 5 on overall step 850.\n",
      "Finished epoch 5 on overall step 851.\n",
      "Finished epoch 5 on overall step 852.\n",
      "Finished epoch 5 on overall step 853.\n",
      "Finished epoch 5 on overall step 854.\n",
      "Finished epoch 5 on overall step 855.\n",
      "Finished epoch 5 on overall step 856.\n",
      "Finished epoch 5 on overall step 857.\n",
      "Finished epoch 5 on overall step 858.\n",
      "Finished epoch 5 on overall step 859.\n",
      "Finished epoch 5 on overall step 860.\n",
      "Finished epoch 5 on overall step 861.\n",
      "Finished epoch 5 on overall step 862.\n",
      "Finished epoch 5 on overall step 863.\n",
      "Finished epoch 5 on overall step 864.\n",
      "Finished epoch 5 on overall step 865.\n",
      "Finished epoch 5 on overall step 866.\n",
      "Finished epoch 5 on overall step 867.\n",
      "Finished epoch 5 on overall step 868.\n",
      "Finished epoch 5 on overall step 869.\n",
      "Finished epoch 5 on overall step 870.\n",
      "Finished epoch 5 on overall step 871.\n",
      "Finished epoch 5 on overall step 872.\n",
      "Finished epoch 5 on overall step 873.\n",
      "Finished epoch 5 on overall step 874.\n",
      "Finished epoch 5 on overall step 875.\n",
      "Finished epoch 5 on overall step 876.\n",
      "Finished epoch 5 on overall step 877.\n",
      "Finished epoch 5 on overall step 878.\n",
      "Finished epoch 5 on overall step 879.\n",
      "Finished epoch 5 on overall step 880.\n",
      "Finished epoch 5 on overall step 881.\n",
      "Finished epoch 5 on overall step 882.\n",
      "Finished epoch 5 on overall step 883.\n",
      "Finished epoch 5 on overall step 884.\n",
      "Finished epoch 5 on overall step 885.\n",
      "Finished epoch 5 on overall step 886.\n",
      "Finished epoch 5 on overall step 887.\n",
      "Finished epoch 5 on overall step 888.\n",
      "Finished epoch 5 on overall step 889.\n",
      "Finished epoch 5 on overall step 890.\n",
      "Finished epoch 5 on overall step 891.\n",
      "Finished epoch 5 on overall step 892.\n",
      "Finished epoch 5 on overall step 893.\n",
      "Finished epoch 5 on overall step 894.\n",
      "Finished epoch 5 on overall step 895.\n",
      "Finished epoch 5 on overall step 896.\n",
      "Finished epoch 5 on overall step 897.\n",
      "Finished epoch 5 on overall step 898.\n",
      "Finished epoch 5 on overall step 899.\n",
      "Finished epoch 5 on overall step 900.\n",
      "Epoch: 5/6..  Training Loss: 0.136..  Validation Loss: 0.169..  Validation Accuracy: 0.936\n",
      "Finished epoch 5 on overall step 901.\n",
      "Finished epoch 5 on overall step 902.\n",
      "Finished epoch 5 on overall step 903.\n",
      "Finished epoch 5 on overall step 904.\n",
      "Finished epoch 5 on overall step 905.\n",
      "Finished epoch 5 on overall step 906.\n",
      "Finished epoch 5 on overall step 907.\n",
      "Finished epoch 5 on overall step 908.\n",
      "Finished epoch 5 on overall step 909.\n",
      "Finished epoch 5 on overall step 910.\n",
      "Finished epoch 6 on overall step 911.\n",
      "Finished epoch 6 on overall step 912.\n",
      "Finished epoch 6 on overall step 913.\n",
      "Finished epoch 6 on overall step 914.\n",
      "Finished epoch 6 on overall step 915.\n",
      "Finished epoch 6 on overall step 916.\n",
      "Finished epoch 6 on overall step 917.\n",
      "Finished epoch 6 on overall step 918.\n",
      "Finished epoch 6 on overall step 919.\n",
      "Finished epoch 6 on overall step 920.\n",
      "Finished epoch 6 on overall step 921.\n",
      "Finished epoch 6 on overall step 922.\n",
      "Finished epoch 6 on overall step 923.\n",
      "Finished epoch 6 on overall step 924.\n",
      "Finished epoch 6 on overall step 925.\n",
      "Finished epoch 6 on overall step 926.\n",
      "Finished epoch 6 on overall step 927.\n",
      "Finished epoch 6 on overall step 928.\n",
      "Finished epoch 6 on overall step 929.\n",
      "Finished epoch 6 on overall step 930.\n",
      "Finished epoch 6 on overall step 931.\n",
      "Finished epoch 6 on overall step 932.\n",
      "Finished epoch 6 on overall step 933.\n",
      "Finished epoch 6 on overall step 934.\n",
      "Finished epoch 6 on overall step 935.\n",
      "Finished epoch 6 on overall step 936.\n",
      "Finished epoch 6 on overall step 937.\n",
      "Finished epoch 6 on overall step 938.\n",
      "Finished epoch 6 on overall step 939.\n",
      "Finished epoch 6 on overall step 940.\n",
      "Finished epoch 6 on overall step 941.\n",
      "Finished epoch 6 on overall step 942.\n",
      "Finished epoch 6 on overall step 943.\n",
      "Finished epoch 6 on overall step 944.\n",
      "Finished epoch 6 on overall step 945.\n",
      "Finished epoch 6 on overall step 946.\n",
      "Finished epoch 6 on overall step 947.\n",
      "Finished epoch 6 on overall step 948.\n",
      "Finished epoch 6 on overall step 949.\n",
      "Finished epoch 6 on overall step 950.\n",
      "Finished epoch 6 on overall step 951.\n",
      "Finished epoch 6 on overall step 952.\n",
      "Finished epoch 6 on overall step 953.\n",
      "Finished epoch 6 on overall step 954.\n",
      "Finished epoch 6 on overall step 955.\n",
      "Finished epoch 6 on overall step 956.\n",
      "Finished epoch 6 on overall step 957.\n",
      "Finished epoch 6 on overall step 958.\n",
      "Finished epoch 6 on overall step 959.\n",
      "Finished epoch 6 on overall step 960.\n",
      "Finished epoch 6 on overall step 961.\n",
      "Finished epoch 6 on overall step 962.\n",
      "Finished epoch 6 on overall step 963.\n",
      "Finished epoch 6 on overall step 964.\n",
      "Finished epoch 6 on overall step 965.\n",
      "Finished epoch 6 on overall step 966.\n",
      "Finished epoch 6 on overall step 967.\n",
      "Finished epoch 6 on overall step 968.\n",
      "Finished epoch 6 on overall step 969.\n",
      "Finished epoch 6 on overall step 970.\n",
      "Finished epoch 6 on overall step 971.\n",
      "Finished epoch 6 on overall step 972.\n",
      "Finished epoch 6 on overall step 973.\n",
      "Finished epoch 6 on overall step 974.\n",
      "Finished epoch 6 on overall step 975.\n",
      "Finished epoch 6 on overall step 976.\n",
      "Finished epoch 6 on overall step 977.\n",
      "Finished epoch 6 on overall step 978.\n",
      "Finished epoch 6 on overall step 979.\n",
      "Finished epoch 6 on overall step 980.\n",
      "Finished epoch 6 on overall step 981.\n",
      "Finished epoch 6 on overall step 982.\n",
      "Finished epoch 6 on overall step 983.\n",
      "Finished epoch 6 on overall step 984.\n",
      "Finished epoch 6 on overall step 985.\n",
      "Finished epoch 6 on overall step 986.\n",
      "Finished epoch 6 on overall step 987.\n",
      "Finished epoch 6 on overall step 988.\n",
      "Finished epoch 6 on overall step 989.\n",
      "Finished epoch 6 on overall step 990.\n",
      "Finished epoch 6 on overall step 991.\n",
      "Finished epoch 6 on overall step 992.\n",
      "Finished epoch 6 on overall step 993.\n",
      "Finished epoch 6 on overall step 994.\n",
      "Finished epoch 6 on overall step 995.\n",
      "Finished epoch 6 on overall step 996.\n",
      "Finished epoch 6 on overall step 997.\n",
      "Finished epoch 6 on overall step 998.\n",
      "Finished epoch 6 on overall step 999.\n",
      "Finished epoch 6 on overall step 1000.\n",
      "Epoch: 6/6..  Training Loss: 0.115..  Validation Loss: 0.170..  Validation Accuracy: 0.938\n",
      "Finished epoch 6 on overall step 1001.\n",
      "Finished epoch 6 on overall step 1002.\n",
      "Finished epoch 6 on overall step 1003.\n",
      "Finished epoch 6 on overall step 1004.\n",
      "Finished epoch 6 on overall step 1005.\n",
      "Finished epoch 6 on overall step 1006.\n",
      "Finished epoch 6 on overall step 1007.\n",
      "Finished epoch 6 on overall step 1008.\n",
      "Finished epoch 6 on overall step 1009.\n",
      "Finished epoch 6 on overall step 1010.\n",
      "Finished epoch 6 on overall step 1011.\n",
      "Finished epoch 6 on overall step 1012.\n",
      "Finished epoch 6 on overall step 1013.\n",
      "Finished epoch 6 on overall step 1014.\n",
      "Finished epoch 6 on overall step 1015.\n",
      "Finished epoch 6 on overall step 1016.\n",
      "Finished epoch 6 on overall step 1017.\n",
      "Finished epoch 6 on overall step 1018.\n",
      "Finished epoch 6 on overall step 1019.\n",
      "Finished epoch 6 on overall step 1020.\n",
      "Finished epoch 6 on overall step 1021.\n",
      "Finished epoch 6 on overall step 1022.\n",
      "Finished epoch 6 on overall step 1023.\n",
      "Finished epoch 6 on overall step 1024.\n",
      "Finished epoch 6 on overall step 1025.\n",
      "Finished epoch 6 on overall step 1026.\n",
      "Finished epoch 6 on overall step 1027.\n",
      "Finished epoch 6 on overall step 1028.\n",
      "Finished epoch 6 on overall step 1029.\n",
      "Finished epoch 6 on overall step 1030.\n",
      "Finished epoch 6 on overall step 1031.\n",
      "Finished epoch 6 on overall step 1032.\n",
      "Finished epoch 6 on overall step 1033.\n",
      "Finished epoch 6 on overall step 1034.\n",
      "Finished epoch 6 on overall step 1035.\n",
      "Finished epoch 6 on overall step 1036.\n",
      "Finished epoch 6 on overall step 1037.\n",
      "Finished epoch 6 on overall step 1038.\n",
      "Finished epoch 6 on overall step 1039.\n",
      "Finished epoch 6 on overall step 1040.\n",
      "Finished epoch 6 on overall step 1041.\n",
      "Finished epoch 6 on overall step 1042.\n",
      "Finished epoch 6 on overall step 1043.\n",
      "Finished epoch 6 on overall step 1044.\n",
      "Finished epoch 6 on overall step 1045.\n",
      "Finished epoch 6 on overall step 1046.\n",
      "Finished epoch 6 on overall step 1047.\n",
      "Finished epoch 6 on overall step 1048.\n",
      "Finished epoch 6 on overall step 1049.\n",
      "Finished epoch 6 on overall step 1050.\n",
      "Finished epoch 6 on overall step 1051.\n",
      "Finished epoch 6 on overall step 1052.\n",
      "Finished epoch 6 on overall step 1053.\n",
      "Finished epoch 6 on overall step 1054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 6 on overall step 1055.\n",
      "Finished epoch 6 on overall step 1056.\n",
      "Finished epoch 6 on overall step 1057.\n",
      "Finished epoch 6 on overall step 1058.\n",
      "Finished epoch 6 on overall step 1059.\n",
      "Finished epoch 6 on overall step 1060.\n",
      "Finished epoch 6 on overall step 1061.\n",
      "Finished epoch 6 on overall step 1062.\n",
      "Finished epoch 6 on overall step 1063.\n",
      "Finished epoch 6 on overall step 1064.\n",
      "Finished epoch 6 on overall step 1065.\n",
      "Finished epoch 6 on overall step 1066.\n",
      "Finished epoch 6 on overall step 1067.\n",
      "Finished epoch 6 on overall step 1068.\n",
      "Finished epoch 6 on overall step 1069.\n",
      "Finished epoch 6 on overall step 1070.\n",
      "Finished epoch 6 on overall step 1071.\n",
      "Finished epoch 6 on overall step 1072.\n",
      "Finished epoch 6 on overall step 1073.\n",
      "Finished epoch 6 on overall step 1074.\n",
      "Finished epoch 6 on overall step 1075.\n",
      "Finished epoch 6 on overall step 1076.\n",
      "Finished epoch 6 on overall step 1077.\n",
      "Finished epoch 6 on overall step 1078.\n",
      "Finished epoch 6 on overall step 1079.\n",
      "Finished epoch 6 on overall step 1080.\n",
      "Finished epoch 6 on overall step 1081.\n",
      "Finished epoch 6 on overall step 1082.\n",
      "Finished epoch 6 on overall step 1083.\n",
      "Finished epoch 6 on overall step 1084.\n",
      "Finished epoch 6 on overall step 1085.\n",
      "Finished epoch 6 on overall step 1086.\n",
      "Finished epoch 6 on overall step 1087.\n",
      "Finished epoch 6 on overall step 1088.\n",
      "Finished epoch 6 on overall step 1089.\n",
      "Finished epoch 6 on overall step 1090.\n",
      "Finished epoch 6 on overall step 1091.\n",
      "Finished epoch 6 on overall step 1092.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"using {} device\".format(device))\n",
    "\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "loss_history = []\n",
    "\n",
    "def train_classifier(epochs, valid_gap):\n",
    "    \n",
    "    \"\"\"\n",
    "    epochs: Number of epochs to train.\n",
    "    valid_gap: Number of iterations between each validation run.\n",
    "    \n",
    "    Trains the model for the specified number of epochs with validation tests. \n",
    "    \"\"\"\n",
    "    \n",
    "    steps = 0\n",
    "    model.to('cuda')\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for images, labels in iter(train_loader):\n",
    "            if steps % valid_gap == 0:\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "                # Turn off gradients for validation, saves memory and computations\n",
    "                with torch.no_grad():\n",
    "                    validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/valid_gap),\n",
    "                      \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
    "                      \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader))) \n",
    "                \n",
    "                val_loss_history.append(validation_loss/len(validate_loader))\n",
    "                val_accuracy_history.append(accuracy/len(validate_loader))\n",
    "                running_loss = 0\n",
    "                model.train()\n",
    "                \n",
    "            steps += 1\n",
    "\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "                \n",
    "            print(f\"Finished epoch {e+1} on overall step {steps}.\")\n",
    "         \n",
    "        \n",
    "    plt.plot(loss_history)\n",
    "    plt.plot(val_loss_history)\n",
    "    plt.plot(val_accuracy_history)\n",
    "    \n",
    "train_classifier(6,100)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12fc36cecd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsaklEQVR4nO3de3RU9b338fcvmVzIlSSTCySBBJKAkJAQbipBQLyAtaJgq1Tboqd2aU9ttc85R5+e9thTl0ufo89z2q7T2sda2+OpCx6PVtTWElRAELxxFQLkQgjkCrmQC7nPzO/5Y0+GSchlEpJM9uT7WitrZvbsvec7IXzmN7/927+ttNYIIYQwPz9vFyCEEGJ0SKALIYSPkEAXQggfIYEuhBA+QgJdCCF8hMVbL2y1WnVKSoq3Xl4IIUzp4MGDdVrr2P6e81qgp6SkcODAAW+9vBBCmJJS6uxAz0mXixBC+AgJdCGE8BES6EII4SMk0IUQwkdIoAshhI+QQBdCCB8hgS6EED7Ca+PQhRBe0N0BbXXQVg+tddDWYDzuaIbAEAiKgOAI521k78cBU0Apb78DMQgJdNFbeyM0lUPjOWgsh+YK0Nr4z2wJHtmtf4C335Vv0ho6Go1QbnWGdFud2/16t+B2hnfXpZG/np+l/8APCndb5n4beeXywFD5UBhDEuiTidbGf+qmc5cDu/Fc7wDvbOq9jSUYlB90twMjvBiK8u8n6IPBMmXw2ylRYM2A2DkwdSb4+V/1r2BCc9ihtbZPONdfvu8KZ7ewdtj635dlCoRaISQaQqxgTYeQGOMn1Oq8b738OCgCutugs9lorfe6bRpgeTM0nnU+boLOFtCOwd+j8nf7AHAG/pSoAepyux8YMvq/bx8kge5LtIZLF5wBfbb/wO5u7b1NYDhMnQFTk2Hm9RCZfPnx1JnGfyaljH3bu4xgt3UM47YDbO2D33Y09Vnu3N7RfblO/yAjlKwZEDsXYjPAOgdiZoMlaHx/z1fD4YCWaqgvgYbTUO/8aTgNDWd6v2d3PaEXYoXoWZC0uHcghzjDu+f+SALQ39mSjhzhe9Pa+AYwnA+EzmZoKIXyz40PKG3vf98BIX3eo/N3ERrjdt96+UMreCr4Tb5DhBLoZuKwQ0uNW0j3De1ysHf23iZ4qhHQMWkw+8Y+gT3DeN6Tr8BKGcE5nuHZ3gh1RVBbCLWnjPuVB6HgLVzfFpQ/RKX0DvnYDCP4g8LHr1Z3Whst6YbTRnDXO28bSo37tvbL61qCjYCOnQNzbjP+XfoG9ZQo8DfBf1WljN95UDiQOPzte7qQBvtW0nO/rshYr28DxVWL/+VvJ67Wfp/gD440vuHYu8De7fzpMj5U3R/bu53LusDes36X27Zuyx19tut3n91w7cOw+sdX89vulwn+SiaplhqoOgLVR6H6CFw4AU2VV7bgQqxGMMfPhznrIHLG5cCOTDZaXGY1ZSokLzV+3HW1QX0x1BZBXaER+HVFUJzfuwsiIql3yMfONe6HxoxOfe2NztAudWtxlxiP3buu/CzGh070bEhdCTGzjA/Y6NkQkTgpW5L9Usr48JoSBaR5tk13+5Vh3+u+s9vqwqnLxxFG0nXoZwG/APAPNI4J9fxcscx5PyDEed/ivA009tHz/PSFw6/BA8pbF4levHixltkWMVolzVVGaFcfdYb4Ebh03rmCMv7zJ2QaoRDp7AqZmgyRScZBJmGwdxvdFj0hX1to3K8rNvqHe4TEOEPe+dPTTx+ReOW3la7Wyy1rVyvb2epuq3NbURn/JtGzjX+vGOdt9Czj38sMLezJwGE3Poh7Rvb49xfU7uHrvD+BPnSVUge11ov7fU4CfRxpbXSNuLe8q45cDgblZ4TLtByYngPTsiEhy3tdB77C4TBG67iHfG2R0Y3T0Xh5vcAw4/cfnWoci6g/DS1VvfcVPs0Z2s6fngCPSjEO5AoxxgYLdGk2jBWt4WJZn5b3UWhvMJ5X/hB3DWTcagT4tGyjFS4t7tHn5+fshpoB6TdfXq61MarEPeTrCqHiAITFw6yVvUM7ehYEhXnvfQgxBAn00eBwwMUzUHX4coBXHzWO7oPxlS7uGrjmdiO4py2E+HnGED7hPUpBWJzxk7rC29UIcdUk0IfLYTe+ivd0l1QfhZovjeFXYPS5xc+H+RuM8J6eA3HzzDW0TghhShLow/HOo3DszctDpSzBEJ8JC77ubHnnGC1xOTNSCOEFEuieaq6GQ69C2s2Q6Wx9W+fI6AUhxIQhaeSp4h3G7c3/anSpCCHEBDNxBldOdMU7jBNV4uZ5uxIhhOiXBLonbJ1wehdk3CIzxQkhJiwJdE+c3WccCE2/1duVCCHEgCTQPVG0w5jtL/UGb1cihBADkkD3RPEO48QTmZNZCDGBSaAPpWeuauluEUJMcBLoQynKN24zbvFuHUIIMQQJ9KEU5xsnEEWleLsSIYQYlAT6YDpboGyftM6FEKYggT6Y0t3GFYKk/1wIYQIS6IMpyjeuTD7jWm9XIoQQQ5JAH4jWUPw+zF4tsycKIUxBAn0g1UfhUo1xRSEhhDABCfSBFO8AlDFdrhBCmIAE+kCK8iExF8JivV2JEEJ4RAK9P611UHlQRrcIIUxFAr0/xe8DWsafCyFMRQK9P8X5EBYPCdnerkQIITwmgd6X3QYlOyH9ZvCTX48Qwjwksfoq/ww6myBduluEEOYigd5XcT74BcCs1d6uRAghhsWjQFdKrVVKFSqlSpRST/bzfKRS6l2l1FGlVIFS6oHRL3WcFO2AmddBcIS3KxFCiGEZMtCVUv7Ar4F1wDxgk1JqXp/V/h44obXOBlYB/1spFTjKtY69xnNQe1KGKwohTMmTFvpSoERrXaq17gK2Auv7rKOBcKWUAsKABsA2qpWOB9fFLCTQhRDm40mgJwLlbo8rnMvc/QdwDVAFHAN+qLV29N2RUuq7SqkDSqkDtbW1Iyx5DBXvgKhUiEnzdiVCCDFsngS66meZ7vP4VuAIMB3IAf5DKXVFJ7TW+iWt9WKt9eLY2Al2Sn1XG5zZY7TOVX9vWQghJjZPAr0CSHZ7nITREnf3APBnbSgBzgBzR6fEcVK2F2wdMlxRCGFangT6F0C6UirVeaDzXuCdPuucA9YAKKXigTlA6WgWOuaK8iEgFFLyvF2JEEKMiGWoFbTWNqXU94F8wB94RWtdoJR62Pn8b4GngT8qpY5hdNE8obWuG8O6R5fWRv/5rFVgCfJ2NUIIMSJDBjqA1vo94L0+y37rdr8KMG9fxYWT0FQON/yDtysRQogRkzNFwTg7FKT/XAhhahLoYJwdmpAFEdO9XYkQQoyYBHr7RWNCLjk7VAhhchLop3eCtsvZoUII05NAL9oBU6IhcZG3KxFCiKsyuQPdYYeS9yHtJvDz93Y1QghxVSZ3oFcegrZ66W4RQviEyR3oxfmg/GD2jd6uRAghrtrkDvSifEheBiHR3q5ECCGu2uQN9OZqqPlSTiYSQviMyRvoxTuMW+k/F0L4iMkd6BFJENf3anpCCGFOkzPQbZ1wehdk3CIXsxBC+IzJGehn90F3q5zuL4TwKZMz0It2gCUYUm/wdiVCCDFqJmegF+dDygoIDPF2JUIIMWpMF+hHyht5dMthWjttI9tBXQk0lMroFiGEzzFdoF/qsPHu0So+L2sY2Q56hivK+HMhhI8xXaAvToki0OLHx8UjvGRpcT7EzoWomaNbmBBCeJnpAj04wJ8lKVHsKxlBoHe2QNk+aZ0LIXyS6QIdIC8tllM1LVxo6RjehqW7wdEtgS6E8EkmDXQrAJ+crh/ehkX5EBQJM64dg6qEEMK7TBno86ZHMDUkYHj96FpD8fswezX4B4xdcUII4SWmDHR/P8X1s2PYV1KH1tqzjaqPwqUaGa4ohPBZpgx0gOVpVqqaOiita/Vsg+IdgIK0m8e0LiGE8BbTBnpPP7rHo12K8iExF8Jix7AqIYTwHtMG+syYUJKjp3jWj95aB5UHZTIuIYRPM22gg9FK/6S0HpvdMfiKxe8D2pguVwghfJSpA315mpWWDhvHKpsGX7E4H8LiISF7fAoTQggvMHWgXz/bg350ezeU7IT0m8HP1G9XCCEGZeqEiw4NZP70CPYO1o9e/hl0Nkn/uRDC55k60MHoRz907iJtXQNMp1u8A/wCjBOKhBDCh5k/0NOtdNs1n58ZYDrdoh0w83oICh/fwoQQYpyZPtCXpEQTaPHrvx+98RzUnpSzQ4UQk4LpAz04wJ/FM6P4uKSfibqK8o1b6T8XQkwCpg90MIYvnqxupu5SZ+8nindAVCrEzPZOYUIIMY58ItD7nQagqw3O7DG6W5TyUmVCCDF+fCLQMxMjiZwS0DvQy/aCrUMuZiGEmDQ8CnSl1FqlVKFSqkQp9eQA66xSSh1RShUopT4a3TIH1zOd7sfFbtPpFuVDQCik5I1nKUII4TVDBrpSyh/4NbAOmAdsUkrN67POVOA3wB1a6/nA10a/1MH1TKdbVt/mvJjFDpi1CixB412KEEJ4hcWDdZYCJVrrUgCl1FZgPXDCbZ1vAH/WWp8D0FpfGO1Ch9LTj/5xSR2p9lZoKocb/mG8yxBiRLq7u6moqKCjY5jXyRU+Kzg4mKSkJAICPL/CmieBngiUuz2uAJb1WScDCFBK7QbCgV9qrV/1uIpRMDMmhMSpU/i4uJZv2vYaC6X/XJhERUUF4eHhpKSkoOQg/qSntaa+vp6KigpSU1M93s6TPvT+/rr6XvfNAiwCvgLcCvxUKZVxxY6U+q5S6oBS6kBtba3HRXpCKUVempX9p+vRRfmQkAUR00f1NYQYKx0dHcTExEiYC8DIs5iYmGF/Y/Mk0CuAZLfHSUBVP+ts11q3aq3rgD3AFXPVaq1f0lov1lovjo0d/SsH5aVbUR2NUP65nEwkTEfCXLgbyd+DJ4H+BZCulEpVSgUC9wLv9FnnbWCFUsqilArB6JI5OexqrtL1s2NY6fclStvldH8hhmHVqlXk5+f3WvaLX/yC733ve4Nuc+DAAQBuu+02Ghsbr1jnZz/7GS+88MKgr71t2zZOnLh8SO5f/uVf+OCDD4ZRff92797N7bffftX7MZMhA11rbQO+D+RjhPTrWusCpdTDSqmHneucBLYDXwKfAy9rrY+PXdn9iwkL4s6wApr9IiFx0Xi/vBCmtWnTJrZu3dpr2datW9m0aZNH27/33ntMnTp1RK/dN9B//vOfc9NNN41oX5OdR+PQtdbvaa0ztNaztdbPOJf9Vmv9W7d1ntdaz9NaZ2qtfzFG9Q7OYec6x2F22bJoH2A2XSHEle6++27+8pe/0NlpTJ9RVlZGVVUVeXl5PPLIIyxevJj58+fz1FNP9bt9SkoKdXXGiX3PPPMMc+bM4aabbqKwsNC1zu9+9zuWLFlCdnY2GzdupK2tjf379/POO+/wj//4j+Tk5HD69Gk2b97MG2+8AcCHH37IwoULycrK4sEHH3TVl5KSwlNPPUVubi5ZWVmcOnXK4/e6ZcsWsrKyyMzM5IknngDAbrezefNmMjMzycrK4t///d8B+NWvfsW8efNYsGAB99577zB/q+PPk1Eu5lF5iBBbIx/Ycpha1sDKjNHvpxdirP3ruwWcqGoe1X3Omx7BU1+dP+DzMTExLF26lO3bt7N+/Xq2bt3KPffcg1KKZ555hujoaOx2O2vWrOHLL79kwYIF/e7n4MGDbN26lcOHD2Oz2cjNzWXRIuPb8oYNG3jooYcA+MlPfsLvf/97Hn30Ue644w5uv/127r777l776ujoYPPmzXz44YdkZGTwrW99ixdffJHHHnsMAKvVyqFDh/jNb37DCy+8wMsvvzzk76GqqoonnniCgwcPEhUVxS233MK2bdtITk6msrKS48eNjoWe7qPnnnuOM2fOEBQU1G+X0kTjE6f+uxTno5U/n6icwS9LJ4S4gnu3i3t3y+uvv05ubi4LFy6koKCgV/dIX3v37uWuu+4iJCSEiIgI7rjjDtdzx48fZ8WKFWRlZfHaa69RUFAwaD2FhYWkpqaSkWEMmPv2t7/Nnj17XM9v2LABgEWLFlFWVubRe/ziiy9YtWoVsbGxWCwW7rvvPvbs2cOsWbMoLS3l0UcfZfv27URERACwYMEC7rvvPv70pz9hsUz89u/Er3A4ivJRyctItyXz8WCXpRNiAhusJT2W7rzzTn70ox9x6NAh2tvbyc3N5cyZM7zwwgt88cUXREVFsXnz5iGH0g00OmPz5s1s27aN7Oxs/vjHP7J79+5B9+OaxmMAQUHGWeD+/v7YbJ71sQ60z6ioKI4ePUp+fj6//vWvef3113nllVf461//yp49e3jnnXd4+umnKSgomNDB7jst9OZqqPkS0m8mL93Kiepm6vtOpyuEGFBYWBirVq3iwQcfdLXOm5ubCQ0NJTIykvPnz/O3v/1t0H3ccMMNvPXWW7S3t9PS0sK7777req6lpYVp06bR3d3Na6+95loeHh5OS0vLFfuaO3cuZWVllJSUAPBf//VfrFy58qre47Jly/joo4+oq6vDbrezZcsWVq5cSV1dHQ6Hg40bN/L0009z6NAhHA4H5eXlrF69mn/7t3+jsbGRS5cuXdXrj7WJ+1EzXMU7jNuMW1neZeX5/EL2n67nq9lycpEQntq0aRMbNmxwdb1kZ2ezcOFC5s+fz6xZs1i+fPmg2+fm5nLPPfeQk5PDzJkzWbFiheu5p59+mmXLljFz5kyysrJcIX7vvffy0EMP8atf/cp1MBSMU9//8Ic/8LWvfQ2bzcaSJUt4+OGHh/V+PvzwQ5KSklyP//u//5tnn32W1atXo7XmtttuY/369Rw9epQHHngAh8MBwLPPPovdbuf++++nqakJrTWPP/74iEfyjBc11NeasbJ48WLdM4Z1VGy9D6qOwOPHsWvI+fkOvpI1jec29n/wRoiJ5OTJk1xzzTXeLkNMMP39XSilDmqtF/e3vm90udg64fQuyLgFlHJNp7vXfTpdIYTwcb4R6Gf3QXdrr9P989KsVDa2c7a+zYuFCSHE+PGNQC/aAZZgSL3BtSgv3RiD/rEMXxRCTBK+EejF+ZCyAgJDXItSnNPpynh0IcRkYf5AryuBhtIrJuNSSrE8LYb9p+uxO6QfXQjh+8wf6MXOGeL6uZjF8jQrTe3dFFQ1jXNRQggx/nwg0HdA7FyImnnFU9fPNi5Lt1fOGhViUL44fW6PH/7whyQmJrrGmPsycwd6ZwuU7RvwUnOx4UHMTQiXfnQhhuCr0+c6HA7eeustkpOTe80DM9rsdvuY7Xs4zB3opbvB0T3oxSxWpFs5UHaR9q6J8QsXYiLy1elzd+3aRWZmJo888ghbtmxxLT9//jx33XUX2dnZZGdns3//fgBeffVVFixYQHZ2Nt/85jcBetUDxhQJYFxAY/Xq1XzjG98gKysLMObDWbRoEfPnz+ell15ybbN9+3Zyc3PJzs5mzZo1OBwO0tPT6bkUp8PhIC0tzfU7HClzn/pflA9BkZDc95rVly1Ps/K7vWc4cLaBFekyna4wgb89CTXHRnefCVmw7rkBn/bV6XO3bNnCpk2bWL9+PT/+8Y/p7u4mICCAH/zgB6xcuZK33noLu93OpUuXKCgo4JlnnmHfvn1YrVYaGhqG/LV+/vnnHD9+3HUh51deeYXo6Gja29tZsmQJGzduxOFw8NBDD7Fnzx5SU1NpaGjAz8+P+++/n9dee43HHnuMDz74gOzsbKxW65CvORjzttC1huL3Ie1G8A8YcLWlqdEE+CsZjy7EEHxt+tyuri7ee+897rzzTiIiIli2bBk7dhhzPu3cuZNHHnkEMGZrjIyMZOfOndx9992uUI2Ojh60PoClS5e6whyMC2JkZ2dz7bXXUl5eTnFxMZ9++ik33HCDa72e/T744IO8+uqrgPFB8MADDwz5ekMxbwu9+ihcqhnyYtAhgRZyZ0RJP7owj0Fa0mPJ16bP3b59O01NTa7ukLa2NkJCQvjKV74y4Ov1V7vFYnEdUNVa09XV5XouNDTUdX/37t188MEHfPLJJ4SEhLBq1So6OjoG3G9ycjLx8fHs3LmTzz77rNcMlCNl3hZ68Q5AQdrQB0/y0qwUVDXT0No15LpCTFa+Nn3uli1bePnllykrK6OsrIwzZ86wY8cO2traWLNmDS+++CJgHNBsbm5mzZo1vP7669TX1wO4ulxSUlI4ePAgAG+//Tbd3d39vl5TUxNRUVGEhIRw6tQpPv30UwCuu+46PvroI86cOdNrvwDf+c53uP/++/n617+Ov7+/x+9tIOYN9KJ8SMyFsKH7xZenW9Ea9p+WVroQg9m0aRNHjx51XT/TffrcBx98cFjT527cuLHf6XNvvvlm5s6d61p+77338vzzz7Nw4UJOnz7tWu4+fW5WVhZ+fn4eT5/b1tZGfn5+r9Z4aGgoeXl5vPvuu/zyl79k165dZGVlsWjRIgoKCpg/fz7//M//zMqVK8nOzuZHP/oRAA899BAfffQRS5cu5bPPPuvVKne3du1abDYbCxYs4Kc//SnXXnstALGxsbz00kts2LCB7Oxs7rnnHtc2d9xxB5cuXRqV7hYw6/S5rXXwfBqs+p+w6okhV7fZHSx8+n1uXzCNZzfIdLpi4pHpcyenAwcO8Pjjj7N3795+nx/u9Lnm7EMvfh/QxnS5HrD4+3HdrBg5MCqEmDCee+45XnzxxVHpO+9hzi6X4nwIi4eEbI83yUu3Ut7QzjmZTlcIMQE8+eSTnD17lry8vFHbp/kC3d4NJTsh/Wbw87z85WnOaQBKaseqMiGE8CrzBXr5Z9DZNORwxb5mWUOZFhkswxfFhCVX1xLuRvL3YL5A97MYQxVnrx7WZsZ0ulaZTldMSMHBwdTX10uoC8AI8/r6eoKDg4e1nfkOis64Fu5/c0Sbrki38sbBCk5UNZOVFDnKhQkxcklJSVRUVLjm9hAiODiYpKSkYW1jvkC/Cj3T6X5cUieBLiaUgICAXqeQCzES5utyuQoyna4QwpdNqkAHY7TL52UNdHTLdLpCCN8y6QI9L81Kl83BgbKL3i5FCCFG1aQLdJlOVwjhqyZdoIcGWVgo0+kKIXzQpAt0MLpdjlc1cVGm0xVC+JBJGejL04zpdD8prfd2KUIIMWomZaBnJ0USFmRhb7F0uwghfMekDHSLvx/XzoqRfnQhhE+ZlIEOkJcWw7mGNplOVwjhMyZvoKcbl67bJ5elE0L4CI8CXSm1VilVqJQqUUo9Och6S5RSdqXU3aNX4tiYHRtKQkSwjEcXQviMIQNdKeUP/BpYB8wDNiml5g2w3v8C8ke7yLHgmk63pA6HTKcrhPABnrTQlwIlWutSrXUXsBVY3896jwJvAhdGsb4xlZcew8W2bk5UN3u7FCGEuGqeBHoiUO72uMK5zEUplQjcBfx2sB0ppb6rlDqglDowEeZ9Xu42na4QQpidJ4Gu+lnWt4/iF8ATWutBpzDUWr+ktV6stV4cGxvrYYljJy4imIz4MBm+KITwCZ5c4KICSHZ7nARU9VlnMbBVKQVgBW5TStm01ttGo8ixlJcWy2ufnaWj205wgL+3yxFCiBHzpIX+BZCulEpVSgUC9wLvuK+gtU7VWqdorVOAN4DvmSHMwehH77Q5OHRWptMVQpjbkIGutbYB38cYvXISeF1rXaCUelgp9fBYFzjWlqbGYPGT6XSFEObn0TVFtdbvAe/1WdbvAVCt9earL2v8hAVZWDhjKh+X1PFP3i5GCCGuwqQ9U9Td8jQrxyqbaGyT6XSFEOYlgY4xP7rW8MlpmU5XCGFeEuhAdvJUwoIs0o8uhDA1CXQgwN+Pa2dFy3h0IYSpSaA7LU+zUlbfRnmDTKcrhDAnCXSnvDRjGgBppQshzEoC3SktLoy48CDpRxdCmJYEupNSirw0K/tP18t0ukIIU5JAd5OXbqWhtYuTNTKdrhDCfCTQ3SyXfnQhhIlJoLuJjwgmPS6MvcUS6EII85FA72N5mpUvyhro6B50anchhJhwJND7yEuz0tHt4NA5mU5XCGEuEuh9LJsVjb+fkn50IYTpSKD3ER4cwMLkqXxcIhN1CSHMRQK9H8vTrByraKSprdvbpQghhMck0PuRl27FoeGTUul2EUKYhwR6P3KSpxIa6C/TAAghTEUCvR8B/n4smxXDPulHF0KYiAT6AJanWTlT10rFRZlOVwhhDhLoA1iRbkwDsF9a6UIIk5BAH0B6XBixMp2uEMJEJNAH0DOd7r6SOplOVwhhChLog1ieZqW+tYtTNS3eLkUIIYYkgT4IuSydEMJMJNAHkRAZTFpcmPSjCyFMQQJ9CHlpVj4/00CnTabTFUJMbBLoQ1ieZqW9287hc43eLkUIIQYlgT6Enul0P5arGAkhJjgJ9CFEBAeQnRQp/ehCiAlPAt0DeWlWvqxopKldptMVQkxcEugeyEuPxaHh01KZBkAIMXFJoHsgJ3kqIYH+Mh5dCDGhSaB7INDix7LUaOlHF0JMaBLoHlqeZqW0tpWqxnZvlyKEEP2SQPdQnnM63Z2nLni5EiGE6J8EuofmxIczIzqEn2w7zl2/2ccf952h7lKnt8sSQggXpbV3poZdvHixPnDggFdee6QuNHfw5qFK3j5SyamaFvz9FMvTrNyZM51b5icQFmTxdolCCB+nlDqotV7c73MS6CNTWNPC20cqeftIFZWN7QQH+HHTNfGsz0lkZUYsgRb58iOEGH1XHehKqbXALwF/4GWt9XN9nr8PeML58BLwiNb66GD7NHug93A4NIfOXWTbkUr++mU1F9u6iZwSwG1Z07gzZzpLUqLx81PeLlMI4SOuKtCVUv5AEXAzUAF8AWzSWp9wW+d64KTW+qJSah3wM631ssH26yuB7q7b7mBvcS1vH6liR8F52rvtTI8M5qs501mfncg108JRSsJdCDFygwW6J52+S4ESrXWpc2dbgfWAK9C11vvd1v8USBp5ueYV4O/HjXPjuXFuPG1dNt4/cZ63j1Tx+71n+L8flZIRH8b6nETuyJ5OcnSIt8sVQvgYTwI9ESh3e1wBDNb6/jvgb/09oZT6LvBdgBkzZnhYojmFBFpYn5PI+pxEGlq7+Ouxat4+XMnz+YU8n1/IoplR3JkznduyphETFuTtcoUQPsCTLpevAbdqrb/jfPxNYKnW+tF+1l0N/AbI01oPOvGJL3a5eKK8oY13v6zi7cNVFJ43RsrckG5lfU4iN8+LJ1RGygghBnG1XS4VQLLb4ySgqp8XWQC8DKwbKswns+ToEL63Ko3vrUrjVE0z2w5X8c6RSh77f0eYEuDPzfPiWZ8znRsyYgnwl5Ey46mysZ1thyvZdeoC10yLYG1mAstSo7HIv4MwCU9a6BaMg6JrgEqMg6Lf0FoXuK0zA9gJfKtPf/qAJmsLvT8Oh+bA2Yu8faSSvx6rprGtm6gQ50iZhYksmhElI2XGSGunje3Ha3jzUAWflNajNcyfHkFpbSvt3XaiQgK46Zp41mUlsDzNSpDF39sli0luNIYt3gb8AmPY4ita62eUUg8DaK1/q5R6GdgInHVuYhvoBXtIoPevy2aMlNl2pIr3T9TQ0e0gceoUbs+expq58eTOmCotxqvkcGg+PVPPmwcr+dvxatq67MyIDmFDbiIbFiYxIyaE9i47HxXVsv14NR+evEBLp42wIAs3zo1jbWYCq+bEEhIo3WNi/MmJRSbV2mmMlNl2pJKPi+uwOTQRwRZuyIjlxrlxrMyIlQOqw1Bae4k/H6rkrcOVVDa2Ex5k4SsLprFxURKLZ0YNOKS0y+Zg3+k68o/XsOPEeRpauwiy+LEyI5Z1WQncODeeyCkB4/xuxGQlge4Dmju6+bi4jl2nLrCrsJa6S50oBQuSpnLjnDhWz40lc3qkdM300dTWzbtfVvHnQxUcOteIn4IV6bFsyE3k1vkJBAcMrwvFZnfwRdlFth+vJr/gPDXNHQT4K66fbWVtZgK3zIuXD9kJTmvN2fo2ztS1YnNotNY4NIBx69Aa7bwF49bhAO28j/M5hwbt3AY9yLaa3sscmkUzo7g+zTqi+iXQfYzDoSmoamZX4QV2nrrA0YpGtAZrWBCr5hit97x0KxHBk7PVaLM72FNcy5sHK3n/5Hm6bA4y4sPYmJvEnQsTiY8IHpXXcTg0RyoayT9ew9+O13CuoQ0/BUtSolmXmcCtmQlMi5wyKq8lRsbh0JxtaONYZRPHK5s4VtHE8aomWjpsXq3r4ZWzeXLd3BFtK4Hu4+ovdfJRUS27Cmv5qPACzR02LH6KRTOjuHFuHKvnxpEeF+bzZ6merG7mzYMVbDtSRd2lTqJCAlifk8jG3CQyEyPG9P1rrTlZ3cL2ghq2H6+m6PwlwLja1drMBNZlJjAzJnTMXl8Y4V1W33o5vCubKKhspqXTCO9Aix/XJISTmRhJVmIk6fFhBPr7oxQoBX5KuW6NL7rGrXI+9nP+/fj5OZc7n8e1jULhXE/h2ka5b+u2r5F+m5ZAn0RsdgeHyxvZdcpovZ+qaQEgceoUVs81Wu/XzbIyJdA3RmvUtnTy9pFK3jxUycnqZgL8FTfOjWNjbhKr5sR5bZK007WX2H68hu3HazhW2QTA3IRw1mVOY21mAhnxvv8BO5bcw/tYhRHeJ6r6hPe0CLISI8hKjCQzMZKM+HCfGAosgT6JVTe1s7uwlp2nLrCvpI62LjuBFj+umxVjtN7nxDEjxlzTEHTa7Hx48gJvHqxgd1EtdodmQVIkG3OT+Gr2dKJDA71dYi8VF9vILzjP9uPVHDh7Ea1hljWUW50t96zESAn3QTgcmjP1ra4uk2OVTRRUNXPJGd5BrvCOdIV3enyYT4R3fyTQBWAE4ednGth1qpbdhRcorWsFYHZsKKvnGF0zS1KiJ+TUv1prDpc38ubBCv7yZTVN7d3ERwRx18IkNuYmkh4f7u0SPXKhpYMdBefJL6hh/+l67A5N4tQp3Do/gbWZCSyaGYX/JD6w7XBoSutaXV0mPS3vfsM7yQjwtDjfDe/+SKCLfpXVtboOrH5W2kCX3UFooD956VZunBvHqjlxo3YAcaSqGtt563Albx6qoLS2leAAP26dn8DG3CSWp1lNHX6NbV18cPIC249Xs6e4ji6bg5BAf9Ljw8mIC2NOQjjp8eHMiQ8nPiLI51rxHd12yupbOVndzLGKZo5XNlFQ1URrlx0wwnve9MtdJlmJkaTHhU368zAk0MWQ2rps7C+pZ2fhBXafukBVUwcA86ZFuMJEYRwgch7zcR3wUc4DRMp5AMlYD9dBItwOIF2xrnNf7uv3BFfxhRb2nzbO3lyaGs3duUmsy0og3AdH71zqtLHr1AUOnbtI0fkWCmsu9brEYUSwhYz4cDISjIBPjw9jTnz4hB8i2dFtp7zBGCJYVt/Kmbo2ypz3q51/YwDBAX7Mm+YW3kmRpMVKePdHAl0Mi9aaovOX2HnqAh+X1NLcbkPTM77WeN5Yzznu1rmNczhur/s943J79tszdtc5nNdY1+2+w2372LAg7siZ7jp7c7JpaO2i6HzL5Z+aSxSeb6Gpvdu1jjUskPS4cOYkhBuBHx9Genz4uJ7o1GVzcK7hclD3hHdZXRtVTe24R0x0aCAzY0JIjQklxWr8zIkPZ3ZsqIS3hyTQhfARWmtqWzopPN9CYU0LxeeNkC8+3+LqqgBIiAh2tubDXN026fFhI56uoNvuoLyhzdXKPusW3JUX250n5hgipwSQYg0lNSbEuLWGkhJj/ESG+N63q/F2tbMtCiEmCKUUcRHBxEUEsyI91rXc4dBUNbW7umuKz7dQeL6F/yytp8vmcK2XHD2FOfE9rXnjZ1ZsKMEB/tjsDiob242grmulrP5yV0nFxXbsbqkdHmQhxRpKTnIUd+UkulrbqTGhRE2wUUaTiQS6ED7Az0+RFBVCUlQIN86Ndy23OzTnGtoorGnp1X2zu7AWmzOg/RTERwRT29LpWgYQGuhPijWUzMRIvrpgurO1HUJKTCjRoYE+d5DWF0igC+HD/P0Uqc5uj7WZCa7lXTYHZfWtrqCvuNhOQmSwW992CLFhvjeyxtdJoAsxCQVa/FxdLsJ3yGFlIYTwERLoQgjhIyTQhRDCR0igCyGEj5BAF0IIHyGBLoQQPkICXQghfIQEuhBC+AivTc6llKoFzo5wcytQN4rlmIG858lB3vPkcDXveabWOra/J7wW6FdDKXVgoNnGfJW858lB3vPkMFbvWbpchBDCR0igCyGEjzBroL/k7QK8QN7z5CDveXIYk/dsyj50IYQQVzJrC10IIUQfEuhCCOEjTBfoSqm1SqlCpVSJUupJb9cz1pRSyUqpXUqpk0qpAqXUD71d03hQSvkrpQ4rpf7i7VrGi1JqqlLqDaXUKee/93XermksKaUed/5NH1dKbVFKBXu7prGglHpFKXVBKXXcbVm0Uup9pVSx8zZqNF7LVIGulPIHfg2sA+YBm5RS87xb1ZizAf9Da30NcC3w95PgPQP8EDjp7SLG2S+B7VrruUA2Pvz+lVKJwA+AxVrrTMAfuNe7VY2ZPwJr+yx7EvhQa50OfOh8fNVMFejAUqBEa12qte4CtgLrvVzTmNJaV2utDznvt2D8J0/0blVjSymVBHwFeNnbtYwXpVQEcAPwewCtdZfWutGrRY09CzBFKWUBQoAqL9czJrTWe4CGPovXA//pvP+fwJ2j8VpmC/REoNztcQU+Hm7ulFIpwELgMy+XMtZ+AfwT4PByHeNpFlAL/MHZ1fSyUirU20WNFa11JfACcA6oBpq01ju8W9W4itdaV4PRaAPiRmOnZgv0/i5BPinGXSqlwoA3gce01s3ermesKKVuBy5orQ96u5ZxZgFygRe11guBVkbpa/hE5OwzXg+kAtOBUKXU/d6tyvzMFugVQLLb4yR89GuaO6VUAEaYv6a1/rO36xljy4E7lFJlGF1qNyql/uTdksZFBVChte759vUGRsD7qpuAM1rrWq11N/Bn4Hov1zSeziulpgE4by+Mxk7NFuhfAOlKqVSlVCDGQZR3vFzTmFJKKYx+1ZNa6//j7XrGmtb6f2qtk7TWKRj/vju11j7fctNa1wDlSqk5zkVrgBNeLGmsnQOuVUqFOP/G1+DDB4H78Q7wbef9bwNvj8ZOLaOxk/GitbYppb4P5GMcFX9Fa13g5bLG2nLgm8AxpdQR57Ifa63f815JYow8CrzmbKyUAg94uZ4xo7X+TCn1BnAIYyTXYXx0CgCl1BZgFWBVSlUATwHPAa8rpf4O48Pta6PyWnLqvxBC+AazdbkIIYQYgAS6EEL4CAl0IYTwERLoQgjhIyTQhRDCR0igCyGEj5BAF0IIH/H/AYhg9MD9BPz8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_history, label = 'Validation Loss')\n",
    "plt.plot(val_accuracy_history, label = \"Validation Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    model.eval()\n",
    "    # Loop over all examples in test set\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model.forward(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        \n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "    \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_UH( models, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    # Loop over all examples in test set\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        model_bad = models[np.random.randint(0,high=len(models))]\n",
    "        output = model_bad.forward(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model_bad.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = models[np.random.randint(0,high=len(models))].forward(perturbed_data)\n",
    "        \n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "    \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 864 / 987 = 0.8753799392097265\n",
      "Epsilon: 0.2\tTest Accuracy = 846 / 987 = 0.8571428571428571\n",
      "Epsilon: 0.4\tTest Accuracy = 849 / 987 = 0.8601823708206687\n",
      "Epsilon: 0.6\tTest Accuracy = 850 / 987 = 0.8611955420466059\n",
      "Epsilon: 0.8\tTest Accuracy = 848 / 987 = 0.8591691995947315\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "epsilons = [0,0.2,0.4,0.6,0.8]\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=1)\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc,ex = test(model,'cuda',test_loader,eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy and Epsilon')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilons, accuracies)\n",
    "plt.title(\"Accuracy and Epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.935157060623169\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(model, test_loader):\n",
    "\n",
    "    # Do validation on the test set\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        accuracy = 0\n",
    "    \n",
    "        for images, labels in iter(test_loader):\n",
    "    \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            \n",
    "            output = model.forward(images)\n",
    "\n",
    "            probabilities = torch.exp(output)\n",
    "        \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
    "        \n",
    "        \n",
    "test_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9493414163589478\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy_uniform_hash(models, test_loader):\n",
    "\n",
    "    # Do validation on the test set\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model.to('cuda')\n",
    "    \n",
    "    n = len(models)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        accuracy = 0\n",
    "    \n",
    "        for images, labels in iter(test_loader):\n",
    "    \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            \n",
    "            output = models[np.random.randint(0,high=n)].forward(images)\n",
    "\n",
    "            probabilities = torch.exp(output)\n",
    "        \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
    "        \n",
    "        \n",
    "test_accuracy_uniform_hash([model1,model2,model3], test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoint\n",
    "\n",
    "def save_checkpoint(model):\n",
    "\n",
    "    model.class_to_idx = training_dataset.class_to_idx\n",
    "\n",
    "    checkpoint = {'arch': \"vgg19\",\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'model_state_dict': model.state_dict()\n",
    "                 }\n",
    "\n",
    "    torch.save(checkpoint, 'model.pth')\n",
    "    \n",
    "save_checkpoint(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    \n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    if checkpoint['arch'] == 'vgg19':\n",
    "        \n",
    "        model = models.vgg19(pretrained=True)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Architecture not recognized.\")\n",
    "    \n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    # Build custom classifier\n",
    "    classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 10, bias= True)),\n",
    "                                        ('tanh1', nn.Tanh()),\n",
    "                                        ('dropout', nn.Dropout(p=0.25)),\n",
    "                                        ('fc2',nn.Linear(10,2,bias=True)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "    model.classifier = classifier\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(\"cuda\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model1 = load_checkpoint('model_1.pth')\n",
    "model2 = load_checkpoint('model_2.pth')\n",
    "model3 = load_checkpoint('model_3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Given an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_image(image_path):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    \n",
    "    pil_image = Image.open(image_path)\n",
    "\n",
    "    \n",
    "    # Resize\n",
    "    if pil_image.size[0] > pil_image.size[1]:\n",
    "        pil_image.thumbnail((5000, 256))\n",
    "    else:\n",
    "        pil_image.thumbnail((256, 5000))\n",
    "        \n",
    "    # Crop \n",
    "    left_margin = (pil_image.width-224)/2\n",
    "    bottom_margin = (pil_image.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    \n",
    "    pil_image = pil_image.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "    \n",
    "    # Normalize\n",
    "    np_image = np.array(pil_image)[:,:,:3]/255\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "    \n",
    "    # PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array\n",
    "    # Color channel needs to be first; retain the order of the other two dimensions.\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "    \n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9943848848342896, 0.00561508210375905]\n",
      "['2', '1']\n",
      "Prediction: Mask\n"
     ]
    }
   ],
   "source": [
    "def predict(image_path, model, topk=2):\n",
    "    \n",
    "    image = process_image(image_path)\n",
    "    #print(image.shape)\n",
    "    \n",
    "    # Convert image to PyTorch tensor first\n",
    "    image = torch.from_numpy(image).type(torch.cuda.FloatTensor)\n",
    "    #print(image.shape)\n",
    "    #print(type(image))\n",
    "    \n",
    "    # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    output = model.forward(image)\n",
    "    \n",
    "    probabilities = torch.exp(output)\n",
    "    \n",
    "    # Probabilities and the indices of those probabilities corresponding to the classes\n",
    "    top_probabilities, top_indices = probabilities.topk(topk)\n",
    "    \n",
    "    # Convert to lists\n",
    "    top_probabilities = top_probabilities.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    top_indices = top_indices.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    \n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "    \n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    #print(idx_to_class)\n",
    "    \n",
    "    top_classes = [idx_to_class[index] for index in top_indices]\n",
    "    \n",
    "    return top_probabilities, top_classes\n",
    "\n",
    "\n",
    "M_i = {'1':'No Mask', '2':'Mask'}\n",
    "\n",
    "probs,classes = predict('doctor.jpg',model)\n",
    "\n",
    "print(probs)\n",
    "print(classes)\n",
    "print(f\"Prediction: {M_i[classes[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_uniform_hash(image_path, models, topk=2):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    image = process_image(image_path)\n",
    "    #print(image.shape)\n",
    "    \n",
    "    # Convert image to PyTorch tensor first\n",
    "    image = torch.from_numpy(image).type(torch.cuda.FloatTensor)\n",
    "    #print(image.shape)\n",
    "    #print(type(image))\n",
    "    \n",
    "    # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    p = np.random.randint(0,len(models))\n",
    "    \n",
    "    print(\"Using model\", p+1)\n",
    "    output = models[np.random.randint(0,len(models))].forward(image)\n",
    "    \n",
    "    probabilities = torch.exp(output)\n",
    "    \n",
    "    # Probabilities and the indices of those probabilities corresponding to the classes\n",
    "    top_probabilities, top_indices = probabilities.topk(topk)\n",
    "    \n",
    "    # Convert to lists\n",
    "    top_probabilities = top_probabilities.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    top_indices = top_indices.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    \n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "    \n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    #print(idx_to_class)\n",
    "    \n",
    "    top_classes = [idx_to_class[index] for index in top_indices]\n",
    "    \n",
    "    return top_probabilities, top_classes\n",
    "\n",
    "M_i = {'1':'No Mask', '2':'Mask'}\n",
    "probs,classes = predict_uniform_hash('aaronzhu2.png',[model1,model2,model3])\n",
    "\n",
    "print(probs)\n",
    "print(classes)\n",
    "print(f\"Prediction: {M_i[classes[0]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
